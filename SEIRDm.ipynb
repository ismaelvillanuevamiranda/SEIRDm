{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GxlQjbRI9-w7",
        "OcsXyxMWL3G7",
        "ZVZybQ8abf_p",
        "n4OCeGabO2eg",
        "AhhLDda8PReE",
        "6cjm-nujPFoz",
        "C9zBaTECbzMF",
        "6a5P4-aj30r6",
        "NOckkZ0AORaI",
        "ouiWh-bGCca0",
        "xAAzYIELdVJX",
        "DNNP_3dxCj1O",
        "y7XfAR599A-h",
        "MdBdQJwDbn1d",
        "Jm_C7_OyR-7G",
        "XRQiW4S0SlW2",
        "y1jjRyjaeyvi",
        "z1lKsEKzOn4F",
        "Ukpu7rB_RUOi",
        "lHxBSaru3WKz",
        "uoJPAeAmau2_",
        "lfOeUixhjsXy",
        "S52Coivquh4G",
        "HfJTIXoPPurz",
        "fwpL9ygB4tpe"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MibPxyvfs6mP"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RST-xh6m6w1l"
      },
      "source": [
        "from google.colab import drive\n",
        "import os, sys\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrAbvDtZbxMU"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iltw4wDwbxMW"
      },
      "source": [
        "# Install libraries\n",
        "!apt install python3-rtree\n",
        "!pip install geopandas\n",
        "!pip install osmnx\n",
        "!pip install contextily\n",
        "!pip install rasterstats\n",
        "!pip install awscli\n",
        "!pip install mapclassify\n",
        "!pip install hvplot\n",
        "!pip install symfit\n",
        "!pip install mpld3\n",
        "!pip install lmfit\n",
        "\n",
        "import os, sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "import osmnx as ox\n",
        "ox.config(use_cache=True, log_console=True)\n",
        "from descartes import PolygonPatch\n",
        "from shapely.geometry import Point, LineString, Polygon, MultiPolygon\n",
        "import contextily as ctx\n",
        "import mapclassify\n",
        "import contextily as ctx\n",
        "import mpld3\n",
        "pd.set_option('display.max_rows', 10000)\n",
        "pd.set_option('display.max_columns', 100000)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByJTG4xJVPFI"
      },
      "source": [
        "# Install AWS to download datasets from SafeGraphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcFbjEx-qyYm"
      },
      "source": [
        "!aws configure --profile safegraphws"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elnns6s1riJm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaofnJsZVWPb"
      },
      "source": [
        "# Download datasets from SafeGraphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd1FJzjMVA_j"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Cr08Gira6w"
      },
      "source": [
        "!aws s3 sync s3://sg-c19-response/social-distancing/v2/ \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/\" --profile safegraphws --exclude \"2019/*\" --exclude \"2020/*\" --endpoint https://s3.wasabisys.com\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmFXSTcazLos"
      },
      "source": [
        "# Loading El Paso CGB information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk_G5gDwzenx"
      },
      "source": [
        "# Loading all the Texas CGB\n",
        "CGB = gpd.read_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/tl_2019_48_bg.shp\"\n",
        ")\n",
        "CGB.plot()\n",
        "# Extracting the El Paso CGB only\n",
        "ELP_CGB = CGB.loc[(CGB[\"STATEFP\"] == \"48\") & (CGB[\"COUNTYFP\"] == \"141\")]\n",
        "print(ELP_CGB.head())\n",
        "print(ELP_CGB.shape)\n",
        "# Saving the El Paso CGB information\n",
        "ELP_CGB.to_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB.shp\"\n",
        ")\n",
        "ELP_CGB.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8oTFczTrr_R"
      },
      "source": [
        "# Extracting population using ELP CGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OH9S68XrrW-"
      },
      "source": [
        "from rasterstats import zonal_stats\n",
        "\n",
        "stats = zonal_stats(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB.shp\",\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/populationDensity/population_usa28_-110_2019-07-01.tif\",\n",
        ")\n",
        "stats[0].keys()\n",
        "population = [f[\"count\"] for f in stats]\n",
        "\n",
        "ELP = gpd.read_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB.shp\"\n",
        ")\n",
        "ELP[\"population\"] = population\n",
        "ELP.to_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_population.shp\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76VnCfFE5WnH"
      },
      "source": [
        "Creating the population matrix (population - mobility)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X-jFajA5XX4"
      },
      "source": [
        "# Function to retrieve the index of a CGB\n",
        "def getIndexFromELPCGBdictionary(df, cgb):\n",
        "    value = df[\"index\"].loc[df[\"CGB\"] == cgb]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "dateRange = (\n",
        "    pd.date_range(\"2020-01\", \"2020-10-25\", freq=\"D\").strftime(\"%Y/%m/%d\").tolist()\n",
        ")\n",
        "\n",
        "# Loading the El Paso population of each CGB\n",
        "ELPCGB_population = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_ZIP_DEMOGRAPHIC.pkl\"\n",
        ")[[\"GEOID\", \"B01001e1\"]]\n",
        "\n",
        "# Loading the ELP CGBs dictionary\n",
        "ELP_CGB_dictionary = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl\"\n",
        ")\n",
        "\n",
        "# Loading the Origin-Destination matrix\n",
        "ODmatrix = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix.npy\"\n",
        ")\n",
        "\n",
        "# Declaring an empty matrix in which the final population (CGB population - mobility) will be stored.\n",
        "pop = np.zeros((len(dateRange), ELP_CGB_dictionary.shape[0]))\n",
        "pop = pop.astype(np.float64)\n",
        "print(pop.shape)\n",
        "\n",
        "# The Z axis. Each timestep represent a day\n",
        "for z in range(len(dateRange)):\n",
        "    # Getting the CGBs and their population\n",
        "    for cgbpop in ELPCGB_population.values:\n",
        "        # Searching the CGB in the dictionary\n",
        "        if cgbpop[0] in ELP_CGB_dictionary[\"CGB\"].values:\n",
        "            # Retrieving the CGB's index\n",
        "            index = getIndexFromELPCGBdictionary(ELP_CGB_dictionary, str(cgbpop[0]))\n",
        "            # Computing the sum of a row. Each row represents a CGB\n",
        "            ODmatrixSumRow = np.sum(ODmatrix[z][index])\n",
        "            # Retrieving the mobility in the same CGB.\n",
        "            ODmatrixSelfCGB = ODmatrix[z][index][index]\n",
        "            # print(str(cgbpop[1]) +\" - \"+ str(ODmatrixSumRow) +\" - \"+str(ODmatrixSelfCGB))\n",
        "            # Computing the total population in each CGB. CGB population - (mobility going out CGB - mobility inside CGB)\n",
        "            pop[z][index] = cgbpop[1]  # - ((ODmatrixSumRow)-(ODmatrixSelfCGB))\n",
        "\n",
        "# Replacing negatives values with zero. This occurs because the number of devices from SafeGraph is not the same number\n",
        "# of population in each CGB. The SafeGraph's data is only a fraction of the population\n",
        "pop[pop <= 0] = 1\n",
        "np.save(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/PopulationMatrixACS2012_2016\",\n",
        "    pop,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THMIFULstMhx"
      },
      "source": [
        "# Mapping ELP CGB to ZIP codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bdVJVc6SP2"
      },
      "source": [
        "# https://www.huduser.gov/portal/datasets/usps_crosswalk.html\n",
        "tract_zip = pd.read_excel(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/TRACT_ZIP_092020.xlsx\"\n",
        ")\n",
        "\n",
        "elpcgb = gpd.read_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB.shp\"\n",
        ")\n",
        "\n",
        "elpcgb[\"ZIP\"] = \"\"\n",
        "elpcgb[\"ZIP_RES_RATIO\"] = \"\"\n",
        "\n",
        "cgbs = elpcgb[\"GEOID\"].values\n",
        "\n",
        "for cgb in cgbs:\n",
        "    zip = tract_zip.loc[tract_zip[\"TRACT\"] == int(cgb[:-1])]\n",
        "    max = zip[zip.RES_RATIO == zip.RES_RATIO.max()]\n",
        "    elpcgb.loc[elpcgb[\"GEOID\"] == str(cgb), [\"ZIP\"]] = max[\"ZIP\"].values[0]\n",
        "    elpcgb.loc[elpcgb[\"GEOID\"] == str(cgb), [\"ZIP_RES_RATIO\"]] = max[\n",
        "        \"RES_RATIO\"\n",
        "    ].values[0]\n",
        "\n",
        "elpcgb = elpcgb.sort_values(by=\"ZIP\", ascending=True)\n",
        "allZIPS1 = elpcgb.ZIP.unique()\n",
        "\n",
        "elpcgb = elpcgb.sort_values(by=\"ZIP\", ascending=True)\n",
        "elpcgb.to_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_508cbgs.shp\"\n",
        ")\n",
        "allZIPS1 = elpcgb.ZIP.unique()\n",
        "\n",
        "allZIPS = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/allZIPS.npy\",\n",
        "    allow_pickle=True,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwM_BEL_bll5"
      },
      "source": [
        "# [DS] Adding Demographic data from Open Census Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFAw8Lq-Ya73"
      },
      "source": [
        "Creating SHP file with all the Demographic Variables\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nEM0iNqbtaS"
      },
      "source": [
        "import tarfile\n",
        "import pandas as pd\n",
        "\n",
        "file = \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/OpenCensusData/safegraph_open_census_data.tar.gz\"\n",
        "\n",
        "# List that contains the demographic tables names\n",
        "tables = [\n",
        "    \"b00\",\n",
        "    \"b01\",\n",
        "    \"b02\",\n",
        "    \"b03\",\n",
        "    \"b07\",\n",
        "    \"b08\",\n",
        "    \"b09\",\n",
        "    \"b11\",\n",
        "    \"b12\",\n",
        "    \"b14\",\n",
        "    \"b15\",\n",
        "    \"b19\",\n",
        "    \"b20\",\n",
        "    \"b21\",\n",
        "    \"b22\",\n",
        "    \"b23\",\n",
        "    \"b25\",\n",
        "    \"b27\",\n",
        "    \"b99\",\n",
        "    \"c16\",\n",
        "    \"c17\",\n",
        "    \"c24\",\n",
        "]\n",
        "# Getting the ELP Census Block Groups\n",
        "cgbs = elpcgb[\"GEOID\"].values\n",
        "\n",
        "# Iterating the demographic tables list\n",
        "for table in tables:\n",
        "    print(table)\n",
        "    # Loading one table at a time\n",
        "    tbl = pd.read_csv(\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/OpenCensusData/safegraph_open_census_data/data/cbg_\"\n",
        "        + table\n",
        "        + \".csv\"\n",
        "    )\n",
        "\n",
        "    # Filtering the columns that contain only the 'e' character, e means 'estimated' value.\n",
        "    tbl = tbl.filter(like=\"e\", axis=1)\n",
        "\n",
        "    # Creating new columns in our dataframe using the columns extracted in the previous line\n",
        "    columns = tbl.columns.values\n",
        "    # Removing first element of the array (census_block_group)\n",
        "    columns = np.delete(columns, 0)\n",
        "    # print(columns)\n",
        "    elpcgb = pd.concat([elpcgb, pd.DataFrame(columns=columns)])\n",
        "\n",
        "    # Iterating the ELP Census Block Groups\n",
        "    for cgb in cgbs:\n",
        "        # Getting the rows for each Census Block Groups. These rows contain the columns values\n",
        "        val = tbl.loc[tbl[\"census_block_group\"] == int(cgb)]\n",
        "        # print(val.shape)\n",
        "        if not val.empty:\n",
        "            # Removing first value of the array (census_block_group)\n",
        "            val = np.delete(val.values[0], 0)\n",
        "            # Assigning the values from the Demographic tables to our dataframe\n",
        "            elpcgb.loc[elpcgb[\"GEOID\"] == str(cgb), columns] = val\n",
        "\n",
        "elpcgb.to_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_ZIP_DEMOGRAPHIC.pkl\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVyMcnNHY03o"
      },
      "source": [
        "Creating SHP file with all the Demographic Variables (PERCENTAGE)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD2ZKnKjY1et"
      },
      "source": [
        "import tarfile\n",
        "import pandas as pd\n",
        "\n",
        "file = \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/OpenCensusData/safegraph_open_census_data.tar.gz\"\n",
        "\n",
        "ELPCGB_ZIP_DEMOGRAPHIC = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_ZIP_DEMOGRAPHIC.pkl\"\n",
        ")\n",
        "\n",
        "columns = ELPCGB_ZIP_DEMOGRAPHIC.columns.values\n",
        "columns = columns[15 : len(columns)]\n",
        "\n",
        "for c in columns:\n",
        "    if c != \"B01001e1\":\n",
        "        ELPCGB_ZIP_DEMOGRAPHIC[c] = (\n",
        "            ELPCGB_ZIP_DEMOGRAPHIC[c] * 100\n",
        "        ) / ELPCGB_ZIP_DEMOGRAPHIC[\"B01001e1\"]\n",
        "\n",
        "ELPCGB_ZIP_DEMOGRAPHIC.to_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_ZIP_DEMOGRAPHIC_PERCENTAGE.pkl\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY15MspPYlBg"
      },
      "source": [
        "Safegraph Open Census Field Description\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR5R5AVKYlsE"
      },
      "source": [
        "fieldDescription = pd.read_csv(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/OpenCensusData/safegraph_open_census_data/cbg_field_descriptions.csv\"\n",
        ")\n",
        "print(fieldDescription.head())\n",
        "print(fieldDescription[[\"table_id\"]].head())\n",
        "\n",
        "t = fieldDescription[fieldDescription[\"table_id\"].str.contains(\"e\")]\n",
        "print(t.shape)\n",
        "print(t.head())\n",
        "t.to_csv(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/OpenCensusData/safegraph_open_census_data/cbg_field_descriptions_estimates.csv\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fZr09SPrqNL"
      },
      "source": [
        "# [DS] Social Distance Metrics - Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHMEAlUtxN4k"
      },
      "source": [
        "Extracting ELP's CGB\n",
        "---\n",
        "TIGER: https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html\n",
        "\n",
        "According to the Topologically Integrated Geographic Encoding and Referencing (TIGER), El Paso county has 513 Census Groups Blocks (CGB). These CGBs were extracted from TIGER, version 2019. All CGB codes are composed by the following rules: two digits for the state, three digits for the county, six digits for the census track, and the last four digits identifies the census block. In our work the digits 48 identifies the Texas state and the digits 141 identifies El Paso county."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovdNUvnDo7od"
      },
      "source": [
        "# Loading all the Texas CGB\n",
        "CGB = gpd.read_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/tl_2019_48_bg.shp\"\n",
        ")\n",
        "CGB.plot()\n",
        "# Extracting the El Paso CGB only\n",
        "ELP_CGB = CGB.loc[(CGB[\"STATEFP\"] == \"48\") & (CGB[\"COUNTYFP\"] == \"141\")]\n",
        "print(ELP_CGB.head())\n",
        "print(ELP_CGB.shape)\n",
        "# Saving the El Paso CGB information\n",
        "ELP_CGB.to_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB.shp\"\n",
        ")\n",
        "ELP_CGB.plot()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_tdNAQPYoy"
      },
      "source": [
        "Creating the ELP CGBs dictionary.\n",
        "---\n",
        "This will be used to create the OD matrix. I need it because the CGBs are in long format and the matrices should have rows and columns starting from 0.\n",
        "\n",
        "elpcgb.to_pickle('/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FDH5Kfo2Suw"
      },
      "source": [
        "ELP_CGB = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_ZIP_DEMOGRAPHIC.pkl\"\n",
        ")\n",
        "ELP_CGB.plot()\n",
        "elpcgb = ELP_CGB[\"GEOID\"]\n",
        "\n",
        "# Sorting the CGBs in ascending order\n",
        "elpcgb = elpcgb.sort_values()\n",
        "\n",
        "# Reseting the index\n",
        "elpcgb = elpcgb.reset_index()\n",
        "\n",
        "# Resetting the index again to convert it into a column\n",
        "elpcgb = elpcgb.reset_index()\n",
        "\n",
        "# Removing the original index column\n",
        "elpcgb.drop(\"index\", inplace=True, axis=1)\n",
        "\n",
        "# Renaming the new columns\n",
        "elpcgb.rename(columns={\"level_0\": \"index\", \"GEOID\": \"CGB\"}, inplace=True)\n",
        "\n",
        "# Saving the dataframe. This is our new dictionary. This will be used to create\n",
        "# the OD matrix. I need it because the CGBs are in long format and the matrices\n",
        "# should have rows and columns starting from 0.\n",
        "# elpcgb.to_pickle('/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl')\n",
        "\n",
        "# print(elpcgb.head())\n",
        "\n",
        "print(elpcgb.shape)\n",
        "print(elpcgb.loc[elpcgb[\"CGB\"] == \"481410103261\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UNKfg3gSjlK"
      },
      "source": [
        "Creating the OD matrix\n",
        "---\n",
        "The OD matrix is created using the Social Distancing Metrics dataset and the ELP CGBs dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znGgzFrM-TBx"
      },
      "source": [
        "import json\n",
        "import ast\n",
        "import os.path\n",
        "\n",
        "\n",
        "def getIndexFromELPCGBdictionary(df, cgb):\n",
        "    value = df[\"index\"].loc[df[\"CGB\"] == cgb]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "# Generating the date range list based on the number of days available in the\n",
        "dateRange = (\n",
        "    pd.date_range(\"2021-01-01\", \"2021-04-16\", freq=\"D\").strftime(\"%Y/%m/%d\").tolist()\n",
        ")\n",
        "\n",
        "# Loading the ELP CGBs dictionary\n",
        "ELP_CGB_dictionary = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl\"\n",
        ")\n",
        "\n",
        "# Declaring an empty OD matrix\n",
        "ODmatrix = np.zeros(\n",
        "    (len(dateRange), ELP_CGB_dictionary.shape[0], ELP_CGB_dictionary.shape[0])\n",
        ")\n",
        "ODmatrix = ODmatrix.astype(np.float64)\n",
        "\n",
        "zIndex = 0\n",
        "\n",
        "for date in dateRange:\n",
        "    # print(date)\n",
        "    print(zIndex)\n",
        "    dateSplit = date.split(\"/\")\n",
        "    file = (\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/\"\n",
        "        + dateSplit[0]\n",
        "        + \"/\"\n",
        "        + dateSplit[0]\n",
        "        + \"-\"\n",
        "        + dateSplit[1]\n",
        "        + \"-\"\n",
        "        + dateSplit[2]\n",
        "        + \"-social-distancing.pkl\"\n",
        "    )\n",
        "    if os.path.isfile(file):\n",
        "        # Reading social distancing metrics file\n",
        "        socialDistancing = pd.read_pickle(file)\n",
        "\n",
        "        # REMOVING all CBGs from the Destination that not are in the CBG dictionary\n",
        "        socialDistancing = socialDistancing[\n",
        "            socialDistancing[\"origin_census_block_group\"].isin(\n",
        "                ELP_CGB_dictionary[\"CGB\"].values\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Updating the index in order to create the 'origin' column in the new frame.\n",
        "        socialDistancing.set_index(\"origin_census_block_group\", inplace=True, drop=True)\n",
        "\n",
        "        # Converting the 'destination_cbgs' column from the string representation of a dictionary to a real dictionary\n",
        "        socialDistancing[\"destination_cbgs\"] = socialDistancing[\n",
        "            \"destination_cbgs\"\n",
        "        ].apply(ast.literal_eval)\n",
        "\n",
        "        # Spliting the dictionaries to access all the elements.\n",
        "        s = socialDistancing[\"destination_cbgs\"].apply(pd.Series).stack().explode()\n",
        "\n",
        "        # Creating the Origin-Destination list\n",
        "        ODlist = s.reset_index()\n",
        "\n",
        "        # REMOVING all CBGs from the Destination that not are in the CBG dictionary\n",
        "        ODlist = ODlist[\n",
        "            ODlist[\"origin_census_block_group\"].isin(ELP_CGB_dictionary[\"CGB\"].values)\n",
        "        ]\n",
        "        ODlist = ODlist[ODlist[\"level_1\"].isin(ELP_CGB_dictionary[\"CGB\"].values)]\n",
        "\n",
        "        # Renaming the columns\n",
        "        ODlist.columns = [\"origin\", \"destination\", \"numberDevices\"]\n",
        "\n",
        "        ODlistValues = ODlist.values\n",
        "\n",
        "        # l = ODlist.head()\n",
        "        # l = l.values\n",
        "        for v in ODlistValues:\n",
        "            if v[1] in ELP_CGB_dictionary[\"CGB\"].values:\n",
        "                row = getIndexFromELPCGBdictionary(ELP_CGB_dictionary, str(v[0]))\n",
        "                col = getIndexFromELPCGBdictionary(ELP_CGB_dictionary, str(v[1]))\n",
        "                ODmatrix[zIndex][row][col] = float(v[2])\n",
        "\n",
        "    zIndex = zIndex + 1\n",
        "np.save(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix_daily_2021\",\n",
        "    ODmatrix,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyQ98O5Xe12u"
      },
      "source": [
        "Create OD-matrix 2019\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHo2_QR6e1PM"
      },
      "source": [
        "# Date Range\n",
        "# dateRange = pd.date_range('2020-01','2020-10-25', freq='D').strftime(\"%Y/%m/%d\").tolist()\n",
        "import json\n",
        "import ast\n",
        "import calendar\n",
        "import os.path\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def getIndexFromELPCGBdictionary(df, cgb):\n",
        "    value = df[\"index\"].loc[df[\"CGB\"] == cgb]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "# Loading the ELP CGBs dictionary\n",
        "ELP_CGB_dictionary = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl\"\n",
        ")\n",
        "\n",
        "# Declaring an empty OD matrix\n",
        "# 84 = 7(SMTWTFS) * 12 (months)\n",
        "ODmatrix = np.zeros((84, ELP_CGB_dictionary.shape[0], ELP_CGB_dictionary.shape[0]))\n",
        "ODmatrix = ODmatrix.astype(np.float64)\n",
        "\n",
        "zIndex = 0\n",
        "\n",
        "year = 2019\n",
        "\n",
        "days = [\"W-SUN\", \"W-MON\", \"W-TUE\", \"W-WED\", \"W-THU\", \"W-FRI\", \"W-SAT\"]\n",
        "\n",
        "for month in range(1, 13):\n",
        "    # month = 12\n",
        "    print(month)\n",
        "\n",
        "    # Get total number of days for a given month\n",
        "    monthTotalDays = calendar.monthrange(year, month)[1]\n",
        "\n",
        "    # First day of each month\n",
        "    startDate = str(month) + \"/01/\" + str(year)\n",
        "    # startDate = str(month)+'/01/2020'\n",
        "\n",
        "    # Last day of each month\n",
        "    endDate = str(month) + \"/\" + str(monthTotalDays) + \"/\" + str(year)\n",
        "    # endDate = str(month)+'/'+str(monthTotalDays)+'/2020'\n",
        "    for d in days:\n",
        "        print(d)\n",
        "        # Get all Sun - Sat of each month\n",
        "        numSMTWTFS = (\n",
        "            pd.date_range(start=str(startDate), end=str(endDate), freq=d)\n",
        "            .strftime(\"%Y/%m/%d\")\n",
        "            .tolist()\n",
        "        )\n",
        "        zIndexMonth = 0\n",
        "        ODmatrixMonth = np.zeros(\n",
        "            (len(numSMTWTFS), ELP_CGB_dictionary.shape[0], ELP_CGB_dictionary.shape[0])\n",
        "        )\n",
        "        ODmatrixMonth = ODmatrixMonth.astype(np.float64)\n",
        "        for date in numSMTWTFS:\n",
        "            # I NEED TO count ALL SUN, MON, ETC inside of this loop.\n",
        "            # print(zIndex)\n",
        "            dateSplit = date.split(\"/\")\n",
        "            file = (\n",
        "                \"/content/drive/MyDrive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/\"\n",
        "                + dateSplit[0]\n",
        "                + \"/\"\n",
        "                + dateSplit[0]\n",
        "                + \"-\"\n",
        "                + dateSplit[1]\n",
        "                + \"-\"\n",
        "                + dateSplit[2]\n",
        "                + \"-social-distancing.pkl\"\n",
        "            )\n",
        "            if os.path.isfile(file):\n",
        "                # # Reading social distancing metrics file\n",
        "                socialDistancing = pd.read_pickle(file)\n",
        "\n",
        "                # REMOVING all CBGs from the Destination that not are in the CBG dictionary\n",
        "                socialDistancing = socialDistancing[\n",
        "                    socialDistancing[\"origin_census_block_group\"].isin(\n",
        "                        ELP_CGB_dictionary[\"CGB\"].values\n",
        "                    )\n",
        "                ]\n",
        "\n",
        "                # # Updating the index in order to create the 'origin' column in the new frame.\n",
        "                socialDistancing.set_index(\n",
        "                    \"origin_census_block_group\", inplace=True, drop=True\n",
        "                )\n",
        "\n",
        "                # # Converting the 'destination_cbgs' column from the string representation of a dictionary to a real dictionary\n",
        "                socialDistancing[\"destination_cbgs\"] = socialDistancing[\n",
        "                    \"destination_cbgs\"\n",
        "                ].apply(ast.literal_eval)\n",
        "\n",
        "                # # Spliting the dictionaries to access all the elements.\n",
        "                s = (\n",
        "                    socialDistancing[\"destination_cbgs\"]\n",
        "                    .apply(pd.Series)\n",
        "                    .stack()\n",
        "                    .explode()\n",
        "                )\n",
        "\n",
        "                # # Creating the Origin-Destination list\n",
        "                ODlist = s.reset_index()\n",
        "\n",
        "                # # REMOVING all CBGs from the Destination that not are in the CBG dictionary\n",
        "                ODlist = ODlist[\n",
        "                    ODlist[\"origin_census_block_group\"].isin(\n",
        "                        ELP_CGB_dictionary[\"CGB\"].values\n",
        "                    )\n",
        "                ]\n",
        "                ODlist = ODlist[\n",
        "                    ODlist[\"level_1\"].isin(ELP_CGB_dictionary[\"CGB\"].values)\n",
        "                ]\n",
        "\n",
        "                # #Renaming the columns\n",
        "                ODlist.columns = [\"origin\", \"destination\", \"numberDevices\"]\n",
        "\n",
        "                ODlistValues = ODlist.values\n",
        "\n",
        "                # # l = ODlist.head()\n",
        "                # # l = l.values\n",
        "                for v in ODlistValues:\n",
        "                    if v[1] in ELP_CGB_dictionary[\"CGB\"].values:\n",
        "                        row = getIndexFromELPCGBdictionary(\n",
        "                            ELP_CGB_dictionary, str(v[0])\n",
        "                        )\n",
        "                        col = getIndexFromELPCGBdictionary(\n",
        "                            ELP_CGB_dictionary, str(v[1])\n",
        "                        )\n",
        "                        ODmatrixMonth[zIndexMonth][row][col] = float(v[2])\n",
        "\n",
        "                zIndexMonth = zIndexMonth + 1\n",
        "\n",
        "        for i in range(0, ODmatrixMonth.shape[0], 1):\n",
        "            np.fill_diagonal(ODmatrixMonth[i], 0)\n",
        "\n",
        "        ODmatrix[zIndex] = np.round(np.nanmedian(ODmatrixMonth, axis=0), 0)\n",
        "        zIndex = zIndex + 1\n",
        "\n",
        "np.save(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrixBaseline2019_nanmedian\",\n",
        "    ODmatrix,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JszRP7VI8Tpp"
      },
      "source": [
        "Remove main diagonal 2019-2020\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KZg4Hn457K0"
      },
      "source": [
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "ODmatrixBaseline2019 = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrixBaseline2019.npy\"\n",
        ")\n",
        "ODmatrixBaseline2020 = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrixBaseline2020.npy\"\n",
        ")\n",
        "\n",
        "inflowMatrix2019 = np.zeros((7, 12)).astype(np.float64)\n",
        "outflowMatrix2019 = np.zeros((7, 12)).astype(np.float64)\n",
        "\n",
        "inflowMatrix2020 = np.zeros((7, 12)).astype(np.float64)\n",
        "outflowMatrix2020 = np.zeros((7, 12)).astype(np.float64)\n",
        "\n",
        "for i in range(0, ODmatrixBaseline2019.shape[0], 1):\n",
        "    np.fill_diagonal(ODmatrixBaseline2019[i], 0)\n",
        "    np.fill_diagonal(ODmatrixBaseline2020[i], 0)\n",
        "\n",
        "sun = list(range(0, 84, 7))\n",
        "mon = list(range(1, 84, 7))\n",
        "tue = list(range(2, 84, 7))\n",
        "wed = list(range(3, 84, 7))\n",
        "thu = list(range(4, 84, 7))\n",
        "fri = list(range(5, 84, 7))\n",
        "sat = list(range(6, 84, 7))\n",
        "\n",
        "days = list(range(0, 7, 1))\n",
        "for day in days:\n",
        "    d2019 = list(range(day, 84, 7))\n",
        "    current = ODmatrixBaseline2019[d2019]\n",
        "    print(current.shape)\n",
        "    for month in range(0, 12, 1):\n",
        "\n",
        "        # outflow\n",
        "        sumRows = np.sum(current[month].sum(axis=1))\n",
        "        outflowMatrix2019[day][month] = sumRows\n",
        "\n",
        "        # inflow\n",
        "        sumRows = np.sum(current[month].sum(axis=0))\n",
        "        inflowMatrix2019[day][month] = sumRows\n",
        "\n",
        "for day in days:\n",
        "    d2019 = list(range(day, 84, 7))\n",
        "    current = ODmatrixBaseline2020[d2019]\n",
        "    print(current.shape)\n",
        "    for month in range(0, 12, 1):\n",
        "\n",
        "        # outflow\n",
        "        sumRows = np.sum(current[month].sum(axis=1))\n",
        "        outflowMatrix2020[day][month] = sumRows\n",
        "\n",
        "        # inflow\n",
        "        sumRows = np.sum(current[month].sum(axis=0))\n",
        "        inflowMatrix2020[day][month] = sumRows\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21EFccem8fBA"
      },
      "source": [
        "Load COVID-19 data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJWUihBKJtQr"
      },
      "source": [
        "dateSave = \"_23_04_2021\"\n",
        "# Reading the ZIP codes\n",
        "allZIPS = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/allZIPS.npy\",\n",
        "    allow_pickle=True,\n",
        ")\n",
        "dfPositives = pd.DataFrame()\n",
        "for zip in allZIPS:\n",
        "    # Read the COVID-19 data for each ZIP\n",
        "    df = pd.read_pickle(\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/\"\n",
        "        + str(int(zip))\n",
        "        + dateSave\n",
        "        + \"_datesFixed.pkl\"\n",
        "    )\n",
        "    dfPositives = pd.concat([dfPositives, df], ignore_index=True)\n",
        "# ===========================================================\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGtL1ALQ8mFR"
      },
      "source": [
        "Create daily-yearly days COVID-19\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPPVfLUwK1UL"
      },
      "source": [
        "import calendar\n",
        "\n",
        "year = 2020\n",
        "\n",
        "days = [\"W-SUN\", \"W-MON\", \"W-TUE\", \"W-WED\", \"W-THU\", \"W-FRI\", \"W-SAT\"]\n",
        "\n",
        "dfCOVID = pd.DataFrame(columns=days)\n",
        "\n",
        "for month in range(1, 13):\n",
        "    # month = 12\n",
        "    print(month)\n",
        "\n",
        "    # Get total number of days for a given month\n",
        "    monthTotalDays = calendar.monthrange(year, month)[1]\n",
        "\n",
        "    # First day of each month\n",
        "    # startDate = str(month)+'/01/2019'\n",
        "    startDate = str(month) + \"/01/2020\"\n",
        "\n",
        "    # Last day of each month\n",
        "    # endDate = str(month)+'/'+str(monthTotalDays)+'/2019'\n",
        "    weekDays = []\n",
        "    endDate = str(month) + \"/\" + str(monthTotalDays) + \"/2020\"\n",
        "    for d in days:\n",
        "        # print(d)\n",
        "        # Get all Sun - Sat of each month\n",
        "        numSMTWTFS = (\n",
        "            pd.date_range(start=str(startDate), end=str(endDate), freq=d)\n",
        "            .strftime(\"%Y/%m/%d\")\n",
        "            .tolist()\n",
        "        )\n",
        "        sel = dfPositives[dfPositives[\"date\"].isin(numSMTWTFS)]\n",
        "        weekDays.append(sel[\"positives\"].sum())\n",
        "    print(weekDays)\n",
        "    dfCOVID = pd.concat(\n",
        "        [dfCOVID, pd.DataFrame([weekDays], columns=dfCOVID.columns)], ignore_index=True\n",
        "    )\n",
        "\n",
        "print(dfCOVID.values.T[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NIfSXBp9I9_"
      },
      "source": [
        "Plot daily mobility and COVID-19\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_m1emYAnVsO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "viz_test = plt\n",
        "\n",
        "viz_test.figure(figsize=(20, 10))\n",
        "\n",
        "SMALL_SIZE = 20\n",
        "MEDIUM_SIZE = 20\n",
        "BIGGER_SIZE = 60\n",
        "\n",
        "# Normalize data\n",
        "dfCOVIDNorm = normalize(dfCOVID.values.T)\n",
        "outflowMatrix2019Norm = normalize(outflowMatrix2019)\n",
        "outflowMatrix2020Norm = normalize(outflowMatrix2020)\n",
        "\n",
        "\n",
        "viz_test.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
        "viz_test.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
        "viz_test.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "viz_test.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
        "viz_test.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "x_pos = [i for i, _ in enumerate(outflowMatrix2019[0])]\n",
        "\n",
        "colors = [\"blue\", \"green\", \"red\", \"blueviolet\", \"magenta\", \"darkorange\", \"black\"]\n",
        "days = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"]\n",
        "for day in range(0, 7, 1):\n",
        "    viz_test.plot(\n",
        "        x_pos,\n",
        "        outflowMatrix2019Norm[day],\n",
        "        color=colors[day],\n",
        "        label=days[day] + \" - 2019\",\n",
        "        marker=\"o\",\n",
        "    )\n",
        "    viz_test.plot(\n",
        "        x_pos,\n",
        "        outflowMatrix2020Norm[day],\n",
        "        color=colors[day],\n",
        "        label=days[day] + \" - 2020\",\n",
        "        marker=\"o\",\n",
        "        linestyle=\"--\",\n",
        "    )\n",
        "    viz_test.plot(\n",
        "        x_pos,\n",
        "        dfCOVIDNorm[day],\n",
        "        color=colors[day],\n",
        "        label=days[day] + \" - COVID-19 2020\",\n",
        "        marker=\"o\",\n",
        "        linestyle=\"dotted\",\n",
        "    )\n",
        "\n",
        "viz_test.title(\"El Paso County, Texas, USA - 2019 Community Mobility Patterns\")\n",
        "viz_test.xlabel(\"\\n2019\")\n",
        "viz_test.ylabel(\"Mobility (Mobile Devices)\")\n",
        "viz_test.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
        "viz_test.grid(axis=\"x\", color=\"0.75\")\n",
        "viz_test.xticks(\n",
        "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
        "    [\n",
        "        \"Jan\",\n",
        "        \"Feb\",\n",
        "        \"Mar\",\n",
        "        \"Apr\",\n",
        "        \"May\",\n",
        "        \"Jun\",\n",
        "        \"Jul\",\n",
        "        \"Aug\",\n",
        "        \"Sep\",\n",
        "        \"Oct\",\n",
        "        \"Nov\",\n",
        "        \"Dec\",\n",
        "    ],\n",
        ")\n",
        "viz_test.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p4ULk1ozaBN"
      },
      "source": [
        "Extract ELP CBGs from SafeGraph\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOdFQOaXJu2I"
      },
      "source": [
        "import os.path\n",
        "\n",
        "dateRange = (\n",
        "    pd.date_range(\"2021-01-01\", \"2021-12-31\", freq=\"D\").strftime(\"%Y/%m/%d\").tolist()\n",
        ")\n",
        "# Loading the ELP CGBs dictionary\n",
        "ELP_CGB_dictionary = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl\"\n",
        ")\n",
        "\n",
        "for date in dateRange:\n",
        "    print(date)\n",
        "    dateSplit = date.split(\"/\")\n",
        "    file = (\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/\"\n",
        "        + dateSplit[0]\n",
        "        + \"/\"\n",
        "        + dateSplit[1]\n",
        "        + \"/\"\n",
        "        + dateSplit[2]\n",
        "        + \"/\"\n",
        "        + dateSplit[0]\n",
        "        + \"-\"\n",
        "        + dateSplit[1]\n",
        "        + \"-\"\n",
        "        + dateSplit[2]\n",
        "        + \"-social-distancing.csv.gz\"\n",
        "    )\n",
        "    if os.path.isfile(file):\n",
        "        socialDistancing = pd.read_csv(file, compression=\"gzip\")\n",
        "        socialDistancing = socialDistancing[\n",
        "            socialDistancing[\"origin_census_block_group\"].isin(\n",
        "                ELP_CGB_dictionary[\"CGB\"].values\n",
        "            )\n",
        "        ]\n",
        "        socialDistancing.to_pickle(\n",
        "            \"/content/drive/MyDrive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/\"\n",
        "            + dateSplit[0]\n",
        "            + \"/\"\n",
        "            + dateSplit[0]\n",
        "            + \"-\"\n",
        "            + dateSplit[1]\n",
        "            + \"-\"\n",
        "            + dateSplit[2]\n",
        "            + \"-social-distancing.pkl\"\n",
        "        )\n",
        "    else:\n",
        "        print(\"File not exist\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ap07TYvWfCY"
      },
      "source": [
        "Create OD-Matrix using Baseline\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Oho-TINWeoF"
      },
      "source": [
        "# createODMatrix(beginDate, endDate, option): This function takes three arguments: beginDate, endDate, and option. \n",
        "# It loads an OD matrix from a file using the np.load() function, depending on the value of option it loads one of \n",
        "# three different files. It then creates a date range using the pd.date_range() function, which takes the beginDate and \n",
        "# endDate arguments as inputs. The function then splits the first date in the date range, and creates a 3D matrix of zeros \n",
        "# with the dimensions of the date range, number of rows, and number of columns. It then loops through the date range, \n",
        "# and for each date, it gets the day of the week, and uses it to index the loaded OD matrix and fill the corresponding \n",
        "# slice of the 3D matrix. Finally, it loops through the 3D matrix and fills the diagonal of each slice with zero.\n",
        "\n",
        "import datetime\n",
        "from datetime import date\n",
        "\n",
        "\n",
        "def createODMatrix(beginDate, endDate, option):\n",
        "    if option == \"mean\":\n",
        "        ODmatrixBaseline2019 = np.load(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrixBaseline2019.npy\"\n",
        "        )\n",
        "    elif option == \"nanmean\":\n",
        "        ODmatrixBaseline2019 = np.load(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrixBaseline2019_nanmean.npy\"\n",
        "        )\n",
        "    elif option == \"nanmedian\":\n",
        "        ODmatrixBaseline2019 = np.load(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrixBaseline2019_nanmedian.npy\"\n",
        "        )\n",
        "\n",
        "    dateRange = (\n",
        "        pd.date_range(beginDate, endDate, freq=\"D\").strftime(\"%Y/%m/%d\").tolist()\n",
        "    )\n",
        "    dateSplit = dateRange[0].split(\"/\")\n",
        "    ODMatrixBaseLine = np.zeros((len(dateRange), 508, 508)).astype(np.float64)\n",
        "\n",
        "    day_name = datetime.date(int(2021), int(5), int(8))\n",
        "    dayNumber = day_name.strftime(\"%w\")\n",
        "\n",
        "    ac = 0\n",
        "    for dateOD in dateRange:\n",
        "        dateSplit = dateOD.split(\"/\")\n",
        "        indexBegin = (int(dateSplit[1]) * 7) - 7\n",
        "\n",
        "        day_name = datetime.date(\n",
        "            int(dateSplit[0]), int(dateSplit[1]), int(dateSplit[2])\n",
        "        )\n",
        "        dayNumber = day_name.strftime(\"%w\")\n",
        "\n",
        "        ODMatrixBaseLine[ac] = ODmatrixBaseline2019[indexBegin + int(dayNumber)]\n",
        "\n",
        "        ac = ac + 1\n",
        "\n",
        "    for i in range(0, ODMatrixBaseLine.shape[0], 1):\n",
        "        np.fill_diagonal(ODMatrixBaseLine[i], 0)\n",
        "\n",
        "    return ODMatrixBaseLine\n",
        "\n",
        "\n",
        "def createODMatrixDayYear(beginDate, endDate):\n",
        "    ODmatrixBaseline2019 = np.load(\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODMatrixBaseline2019_v2.npy\"\n",
        "    )\n",
        "    dateRange = (\n",
        "        pd.date_range(beginDate, endDate, freq=\"D\").strftime(\"%Y/%m/%d\").tolist()\n",
        "    )\n",
        "    dateRange.remove(\"2020/02/29\")\n",
        "\n",
        "    dateSplit = dateRange[0].split(\"/\")\n",
        "    ODMatrixBaseLine = np.zeros((len(dateRange), 508, 508)).astype(np.float64)\n",
        "\n",
        "    ac = 0\n",
        "    for dateOD in dateRange:\n",
        "        dateSplit = dateOD.split(\"/\")\n",
        "        indexBegin = (int(dateSplit[1]) * 7) - 7\n",
        "\n",
        "        day_name = datetime.date(\n",
        "            int(dateSplit[0]), int(dateSplit[1]), int(dateSplit[2])\n",
        "        )\n",
        "        dayNumber = day_name.strftime(\"%w\")\n",
        "        ODMatrixBaseLine[ac] = ODmatrixBaseline2019[indexBegin + int(dayNumber)]\n",
        "        ac = ac + 1\n",
        "\n",
        "    return ODMatrixBaseLine\n",
        "\n",
        "\n",
        "ODMatrixBaseLine = createODMatrixDayYear(\"2020-01-01\", \"2021-12-31\")\n",
        "np.save(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODMatrixBaseLine-2020-01-01_2021-12-31\",\n",
        "    ODMatrixBaseLine,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56dGd7Tt8ogu"
      },
      "source": [
        "Plot Mobility baseline 2019 & mobility 2020\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJSntFceWuAI"
      },
      "source": [
        "# This code is used to create and plot a comparison of daily outflow (OD) matrices for the years 2019, 2020, \n",
        "# and 2021. The code first loads three pre-calculated OD matrices for each year: 'ODmatrix_daily_2019', \n",
        "# 'ODmatrix_daily_2020', and 'ODmatrix_daily_2021'. It then removes Feb 29th from the 2020 matrix, as it is a leap year, \n",
        "# and fills the diagonal of each matrix with zeroes. The code then uses the matplotlib library to create a line plot of the normalized OD matrix sums over the year 2019, \n",
        "# 2020, and 2021.\n",
        "\n",
        "from datetime import datetime, date\n",
        "import datetime\n",
        "from datetime import date\n",
        "\n",
        "# Specific date\n",
        "day_of_year = date(2020, 2, 29).timetuple().tm_yday\n",
        "dateRange2020 = (\n",
        "    pd.date_range(\"2020-01-01\", \"2020-12-31\", freq=\"D\").strftime(\"%b-%d\").tolist()\n",
        ")\n",
        "dateRange2020.remove(\"Feb-28\")\n",
        "ticks = [\n",
        "    1,\n",
        "    15,\n",
        "    30,\n",
        "    45,\n",
        "    60,\n",
        "    75,\n",
        "    90,\n",
        "    105,\n",
        "    120,\n",
        "    135,\n",
        "    150,\n",
        "    165,\n",
        "    180,\n",
        "    195,\n",
        "    210,\n",
        "    225,\n",
        "    240,\n",
        "    255,\n",
        "    270,\n",
        "    285,\n",
        "    300,\n",
        "    315,\n",
        "    330,\n",
        "    345,\n",
        "    360,\n",
        "]\n",
        "dateRange2020Labels = [\"\"] * len(dateRange2020)\n",
        "for i in ticks:\n",
        "    dateRange2020Labels[i - 1] = dateRange2020[i - 1]\n",
        "\n",
        "ODmatrix_daily_2019 = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix_daily_2019.npy\"\n",
        ")\n",
        "ODmatrix_daily_2020 = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix_daily_2020.npy\"\n",
        ")\n",
        "ODmatrix_daily_2021 = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix_daily_2021.npy\"\n",
        ")\n",
        "\n",
        "ODmatrix_daily_2020 = np.delete(ODmatrix_daily_2020, [day_of_year], axis=0)\n",
        "\n",
        "for i in range(0, ODmatrix_daily_2019.shape[0], 1):\n",
        "    np.fill_diagonal(ODmatrix_daily_2019[i], 0)\n",
        "\n",
        "for i in range(0, ODmatrix_daily_2020.shape[0], 1):\n",
        "    np.fill_diagonal(ODmatrix_daily_2020[i], 0)\n",
        "\n",
        "for i in range(0, ODmatrix_daily_2021.shape[0], 1):\n",
        "    np.fill_diagonal(ODmatrix_daily_2021[i], 0)\n",
        "\n",
        "sum2019 = ODmatrix_daily_2019.sum(axis=(1, 2))\n",
        "sum2020 = ODmatrix_daily_2020.sum(axis=(1, 2))\n",
        "sum2021_ = ODmatrix_daily_2021.sum(axis=(1, 2))\n",
        "sum2021_[sum2021_ == 0] = sum2021_.mean()\n",
        "\n",
        "\n",
        "sum2021 = np.empty(sum2019.shape[0])\n",
        "sum2021[:] = np.NaN\n",
        "sum2021[0 : sum2021_.shape[0]] = sum2021_\n",
        "\n",
        "sum2019[sum2019 == 0] = \"nan\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "viz_test = plt\n",
        "\n",
        "viz_test.figure(figsize=(20, 10))\n",
        "\n",
        "SMALL_SIZE = 20\n",
        "MEDIUM_SIZE = 20\n",
        "BIGGER_SIZE = 60\n",
        "\n",
        "viz_test.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
        "viz_test.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
        "viz_test.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "viz_test.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
        "viz_test.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "x_pos = [i for i, _ in enumerate(sum2020)]\n",
        "\n",
        "colors = [\n",
        "    \"blue\",\n",
        "    \"green\",\n",
        "    \"red\",\n",
        "    \"blueviolet\",\n",
        "    \"magenta\",\n",
        "    \"darkorange\",\n",
        "    \"black\",\n",
        "    \"silver\",\n",
        "    \"cornflowerblue\",\n",
        "    \"mediumpurple\",\n",
        "    \"dimgray\",\n",
        "]\n",
        "days = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"]\n",
        "# for day in range(0,len(sum2020),1):\n",
        "viz_test.plot(\n",
        "    x_pos, sum2019, \"--\", color=colors[10], label=\"Mobility 2019 - Baseline\"\n",
        ")  # , marker='o')\n",
        "viz_test.plot(x_pos, sum2020, color=colors[8], label=\"Mobility 2020\")  # , marker='o')\n",
        "viz_test.plot(x_pos, sum2021, color=colors[9], label=\"Mobility 2021\")  # , marker='o')\n",
        "\n",
        "viz_test.title(\"El Paso County, Texas, USA - Community Mobility Patterns\")\n",
        "viz_test.xlabel(\"\\nDays\")\n",
        "viz_test.ylabel(\"Mobility (Mobile Devices)\")\n",
        "\n",
        "viz_test.legend()\n",
        "\n",
        "viz_test.xticks(x_pos, dateRange2020Labels, rotation=\"vertical\")\n",
        "viz_test.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcsXyxMWL3G7"
      },
      "source": [
        "Compute avg day/year (Sun to Sat)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbvDEPki1bMA"
      },
      "source": [
        "import datetime\n",
        "from datetime import date\n",
        "import calendar\n",
        "\n",
        "# Function to retrun all Mondays, Tuesdays, etc for a year\n",
        "def allDays(ODmatrix_daily_2019, year, month, day):\n",
        "\n",
        "    # Counter to track the index\n",
        "    i = 0\n",
        "\n",
        "    # Get total number of days for a given month\n",
        "    monthTotalDays = calendar.monthrange(year, month)[1]\n",
        "\n",
        "    # First day of each month\n",
        "    startDate = str(month) + \"/01/\" + str(year)\n",
        "\n",
        "    # Last day of each month\n",
        "    endDate = str(month) + \"/\" + str(monthTotalDays) + \"/\" + str(year)\n",
        "\n",
        "    # Get the 'day' of the 'year'. 'day' can be SUN, MON, TUE, WED, THU, FRI, SAT\n",
        "    # days = pd.date_range(start=str(year), end=str(year+1), freq='W-'+day).strftime('%Y/%m/%d').tolist()\n",
        "    days = (\n",
        "        pd.date_range(start=str(startDate), end=str(endDate), freq=\"W-\" + day)\n",
        "        .strftime(\"%Y/%m/%d\")\n",
        "        .tolist()\n",
        "    )\n",
        "    # Create the np array that will hold the number of the days\n",
        "    daysNumber = np.zeros((len(days))).astype(np.float64)\n",
        "    ODMatrix = np.zeros((len(days), 508, 508)).astype(np.float64)\n",
        "\n",
        "    # print(monthTotalDays, startDate, endDate)\n",
        "    for day in days:\n",
        "        # Split the day (dates)\n",
        "        dateSplit = day.split(\"/\")\n",
        "        # Get the day name\n",
        "        day_name = datetime.date(\n",
        "            int(dateSplit[0]), int(dateSplit[1]), int(dateSplit[2])\n",
        "        )\n",
        "        # Get the number day\n",
        "        dayNumber = int(day_name.strftime(\"%j\")) - 1\n",
        "        # Add the number day to the daysNumber array\n",
        "        daysNumber[i] = dayNumber\n",
        "        np.fill_diagonal(ODmatrix_daily_2019[int(dayNumber)], 0)\n",
        "        ODMatrix[i] = ODmatrix_daily_2019[int(dayNumber)]\n",
        "        i = i + 1\n",
        "    averageDay = np.round(np.sum(ODMatrix.sum(axis=(0, 1))) / ODMatrix.shape[0], 0)\n",
        "    return days, daysNumber, ODMatrix, averageDay\n",
        "\n",
        "\n",
        "ODmatrix_daily_2019 = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix_daily_2019.npy\"\n",
        ")\n",
        "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
        "dayWeek = [\"SUN\", \"MON\", \"TUE\", \"WED\", \"THU\", \"FRI\", \"SAT\"]\n",
        "daysYearAvg = np.zeros((len(months) * len(dayWeek))).astype(np.float64)\n",
        "ODMatrixBaseline2019 = np.zeros((len(months) * len(dayWeek), 508, 508)).astype(\n",
        "    np.float64\n",
        ")\n",
        "i = 0\n",
        "year = 2019\n",
        "z = 0\n",
        "for month in months:\n",
        "    for day in dayWeek:\n",
        "        # Counter to track the index\n",
        "        j = 0\n",
        "\n",
        "        # Get total number of days for a given month\n",
        "        monthTotalDays = calendar.monthrange(year, month)[1]\n",
        "\n",
        "        # First day of each month\n",
        "        startDate = str(month) + \"/01/\" + str(year)\n",
        "\n",
        "        # Last day of each month\n",
        "        endDate = str(month) + \"/\" + str(monthTotalDays) + \"/\" + str(year)\n",
        "\n",
        "        # Get the 'day' of the 'year'. 'day' can be SUN, MON, TUE, WED, THU, FRI, SAT\n",
        "        # days = pd.date_range(start=str(year), end=str(year+1), freq='W-'+day).strftime('%Y/%m/%d').tolist()\n",
        "        days = (\n",
        "            pd.date_range(start=str(startDate), end=str(endDate), freq=\"W-\" + day)\n",
        "            .strftime(\"%Y/%m/%d\")\n",
        "            .tolist()\n",
        "        )\n",
        "        # Create the np array that will hold the number of the days\n",
        "        daysNumber = np.zeros((len(days))).astype(np.float64)\n",
        "        ODMatrix = np.zeros((len(days), 508, 508)).astype(np.float64)\n",
        "\n",
        "        for day in days:\n",
        "            # Split the day (dates)\n",
        "            dateSplit = day.split(\"/\")\n",
        "            # Get the day name\n",
        "            day_name = datetime.date(\n",
        "                int(dateSplit[0]), int(dateSplit[1]), int(dateSplit[2])\n",
        "            )\n",
        "            # Get the number day\n",
        "            dayNumber = int(day_name.strftime(\"%j\")) - 1\n",
        "            # Add the number day to the daysNumber array\n",
        "            daysNumber[j] = dayNumber\n",
        "            np.fill_diagonal(ODmatrix_daily_2019[int(dayNumber)], 0)\n",
        "            ODMatrix[j] = ODmatrix_daily_2019[int(dayNumber)]\n",
        "            j = j + 1\n",
        "            z = z + 1\n",
        "        averageDay = np.round(np.sum(ODMatrix.sum(axis=(0))) / ODMatrix.shape[0], 0)\n",
        "        ODMatrixBaseline2019[i] = ODMatrix.sum(axis=(0)) / ODMatrix.shape[0]\n",
        "\n",
        "        daysYearAvg[i] = averageDay\n",
        "        i = i + 1\n",
        "np.save(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODMatrixBaseline2019_v2\",\n",
        "    ODMatrixBaseline2019,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDyAQGoNQdTw"
      },
      "source": [
        "# ZIP to CBG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vs9PFL7FAiV"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "dfStats = pd.DataFrame(columns=[\"ZIP\", \"POSITIVE ESTIMATED\", \"POSITIVES\"])\n",
        "\n",
        "ELPCGB_ZIP_DEMOGRAPHIC = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_ZIP_DEMOGRAPHIC.pkl\"\n",
        ")\n",
        "elp_ZIP_POP_COVID = ELPCGB_ZIP_DEMOGRAPHIC[\n",
        "    [\"GEOID\", \"INTPTLAT\", \"geometry\", \"ZIP\", \"ZIP_RES_RATIO\", \"B01001e1\"]\n",
        "].copy()\n",
        "\n",
        "dates = pd.date_range(\"01-01-2020\", \"20-04-2021\", freq=\"B\")\n",
        "# Adding new columns. Each new column is a day\n",
        "dateSave = \"_23_04_2021\"\n",
        "# Reading the ZIP codes\n",
        "allZIPS = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/allZIPS.npy\",\n",
        "    allow_pickle=True,\n",
        ")\n",
        "for zip in allZIPS:\n",
        "    print(zip)\n",
        "    # Read the COVID-19 data for each ZIP\n",
        "    df = pd.read_pickle(\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/\"\n",
        "        + str(int(zip))\n",
        "        + dateSave\n",
        "        + \"_datesFixed.pkl\"\n",
        "    )\n",
        "    # Load these columns only\n",
        "    date_positives = df[[\"date\", \"positives\", \"recoveries\", \"deaths\"]]\n",
        "\n",
        "    # Change the 'date' column from datetime to str\n",
        "    date_positives[\"date\"] = date_positives[\"date\"].astype(str)\n",
        "\n",
        "    # Select all CBGs that belong to a ZIP\n",
        "    zipSelected = elp_ZIP_POP_COVID.loc[elp_ZIP_POP_COVID[\"ZIP\"] == zip].copy()  # GEOID\n",
        "    # Change the datatype of the columns\n",
        "    zipSelected[\"ZIP\"] = zipSelected[\"ZIP\"].astype(float)\n",
        "    zipSelected[\"ZIP_RES_RATIO\"] = zipSelected[\"ZIP_RES_RATIO\"].astype(float)\n",
        "    zipSelected[\"B01001e1\"] = zipSelected[\"B01001e1\"].astype(float)\n",
        "\n",
        "    # ZIP total population\n",
        "    sumPop = zipSelected[\"B01001e1\"].sum()\n",
        "\n",
        "    # Computing the ratios of each CBG using the total population\n",
        "    ratios = zipSelected[\"B01001e1\"] / sumPop\n",
        "\n",
        "    for index, row in date_positives.iterrows():\n",
        "        posEst = pd.DataFrame()\n",
        "        # Estimate the positive cases in each CBG using the total positive cases for a given ZIP\n",
        "        # Estimations without round\n",
        "        posEstRaw = (row[\"positives\"] * ratios) / (ratios.sum())\n",
        "        # Estimations rounded\n",
        "        posEst = np.round(posEstRaw, 0)\n",
        "        # Compute the difference between the REAL values - estimations\n",
        "        estDiff = row[\"positives\"] - np.sum(posEst)\n",
        "        # print('estDiff: '+str(estDiff))\n",
        "        # If underestimate\n",
        "        if estDiff > 0:\n",
        "            # Sort in descending order the raw estimations\n",
        "            top = posEstRaw.sort_values(ascending=False)\n",
        "            # Get the top N = estDiff estimations and adds 1\n",
        "            temp = np.round(top.head(int(estDiff)) + 1)\n",
        "            # print(temp)\n",
        "            # Update the posEst values with the new values\n",
        "            posEst.loc[temp.index.values] = temp.values\n",
        "\n",
        "        # If overestimate\n",
        "        elif estDiff < 0:\n",
        "            # Convert to positive\n",
        "            estDiff = estDiff * -1\n",
        "            # Sort in descending order the raw estimations\n",
        "            top = posEstRaw.sort_values(ascending=False)\n",
        "            # Get the top N = estDiff estimation\n",
        "            top = top.head(int(estDiff))\n",
        "            # Sort in ascending order the raw values to substract 1 to the less important CBG\n",
        "            top = top.sort_values(ascending=True)\n",
        "            # Substract 1 and round up\n",
        "            temp = np.round(top - 1, 0)\n",
        "            # Update the posEst values with the new values\n",
        "            posEst.loc[temp.index.values] = temp.values\n",
        "\n",
        "        for cell in posEst.index:\n",
        "            elp_ZIP_POP_COVID.at[cell, row[\"date\"]] = posEst.loc[cell]\n",
        "\n",
        "        dfStats = dfStats.append(\n",
        "            {\n",
        "                \"ZIP\": zip,\n",
        "                \"POSITIVE ESTIMATED\": np.sum(posEst),\n",
        "                \"POSITIVES\": row[\"positives\"],\n",
        "            },\n",
        "            ignore_index=True,\n",
        "        )\n",
        "        # print('-'*20)\n",
        "elp_ZIP_POP_COVID.to_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/elp_ZIP_POP_COVID_V2.pkl\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWNM0vyJyumY"
      },
      "source": [
        "# ELP Strong Web Scrapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq6jXvrL4kHC"
      },
      "source": [
        "Web Scrapping\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiQa_QJrdaCD"
      },
      "source": [
        "import re\n",
        "import json\n",
        "import base64\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.epstrong.org/results.php\"\n",
        "\n",
        "soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
        "html_data = requests.get(soup.iframe[\"src\"]).text\n",
        "\n",
        "d = json.loads(base64.b64decode(soup.iframe[\"src\"].split(\"=\")[-1]).decode(\"utf-8\"))\n",
        "\n",
        "tenantId = d[\"t\"]\n",
        "resourceKey = d[\"k\"]\n",
        "resolvedClusterUri = re.search(r\"var resolvedClusterUri = '(.*?)'\", html_data)[\n",
        "    1\n",
        "].replace(\"-redirect\", \"-api\")\n",
        "requestId = re.search(r\"var requestId = '(.*?)'\", html_data)[1]\n",
        "activityId = re.search(r\"var telemetrySessionId =  '(.*?)'\", html_data)[1]\n",
        "\n",
        "# https://wabi-us-north-central-b-api.analysis.windows.net/public/reports/686caa65-2ec0-49e7-86c6-a58220a4a3ef/modelsAndExploration?preferReadOnlySession=true\n",
        "url = (\n",
        "    resolvedClusterUri\n",
        "    + \"public/reports/\"\n",
        "    + resourceKey\n",
        "    + \"/modelsAndExploration?preferReadOnlySession=true\"\n",
        ")\n",
        "\n",
        "# https://wabi-us-north-central-b-api.analysis.windows.net/public/reports/querydata?synchronous=true\n",
        "query_url = resolvedClusterUri + \"public/reports/querydata?synchronous=true\"\n",
        "\n",
        "# {'ActivityId': '54b68dbe-c5b1-46dc-99a8-8169388e9f2c', 'RequestId': '4f8900f0-7bc5-466b-b530-2ed8477f3638', 'X-PowerBI-ResourceKey': '686caa65-2ec0-49e7-86c6-a58220a4a3ef'}\n",
        "headers = {\n",
        "    \"ActivityId\": activityId,\n",
        "    \"RequestId\": requestId,\n",
        "    \"X-PowerBI-ResourceKey\": resourceKey,\n",
        "}\n",
        "# print(headers)\n",
        "\n",
        "ELPCGB_ZIP_DEMOGRAPHIC = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_ZIP_DEMOGRAPHIC.pkl\"\n",
        ")\n",
        "ELPCGB_ZIP_DEMOGRAPHIC = ELPCGB_ZIP_DEMOGRAPHIC.sort_values(by=\"ZIP\", ascending=True)\n",
        "allZIPS = ELPCGB_ZIP_DEMOGRAPHIC.ZIP.unique()\n",
        "# print((allZIPS))\n",
        "\n",
        "# Fort Bliss\n",
        "# https://texas.hometownlocator.com/zip-codes/map,zipcode,79906.cfm\n",
        "allZIPS = allZIPS[allZIPS != 79906.0]\n",
        "\n",
        "# Empty ZIP? It seems that nobody lives here\n",
        "# ZIP Code 79929 is contained within ZIP Code 79928 and perhaps demographic information for this ZIP Code would be of interest to\n",
        "allZIPS = allZIPS[allZIPS != 79929.0]\n",
        "\n",
        "# ZIP Code 79995 is contained within ZIP Code 79905 and perhaps demographic information for this ZIP Code would be of interest to\n",
        "allZIPS = allZIPS[allZIPS != 79995.0]\n",
        "\n",
        "# ZIP Code 79913 is contained within ZIP Code 79912 and perhaps demographic information for this ZIP Code would be of interest to\n",
        "allZIPS = allZIPS[allZIPS != 79913.0]\n",
        "\n",
        "# https://texas.hometownlocator.com/zip-codes/map,zipcode,79908.cfm\n",
        "allZIPS = allZIPS[allZIPS != 79908.0]\n",
        "\n",
        "# ZIP Code 79996 is contained within ZIP Code 79936 and perhaps demographic information for this ZIP Code\n",
        "allZIPS = allZIPS[allZIPS != 79996.0]\n",
        "\n",
        "allZIPS = np.append(allZIPS, 79911.0)\n",
        "allZIPS = allZIPS.astype(int)\n",
        "\n",
        "for zip in allZIPS:\n",
        "    # print(zip)\n",
        "    payload = {\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"queries\": [\n",
        "            {\n",
        "                \"Query\": {\n",
        "                    \"Commands\": [\n",
        "                        {\n",
        "                            \"SemanticQueryDataShapeCommand\": {\n",
        "                                \"Query\": {\n",
        "                                    \"Version\": 2,\n",
        "                                    \"From\": [\n",
        "                                        {\n",
        "                                            \"Name\": \"m\",\n",
        "                                            \"Entity\": \"Measures Table\",\n",
        "                                            \"Type\": 0,\n",
        "                                        },\n",
        "                                        {\n",
        "                                            \"Name\": \"d\",\n",
        "                                            \"Entity\": \"Dashboard Data RedCap\",\n",
        "                                            \"Type\": 0,\n",
        "                                        },\n",
        "                                    ],\n",
        "                                    \"Select\": [\n",
        "                                        {\n",
        "                                            \"Measure\": {\n",
        "                                                \"Expression\": {\n",
        "                                                    \"SourceRef\": {\"Source\": \"m\"}\n",
        "                                                },\n",
        "                                                \"Property\": \"Cumulative Cases\",\n",
        "                                            },\n",
        "                                            \"Name\": \"Measures Table.Cumulative Cases\",\n",
        "                                        },\n",
        "                                        {\n",
        "                                            \"Measure\": {\n",
        "                                                \"Expression\": {\n",
        "                                                    \"SourceRef\": {\"Source\": \"m\"}\n",
        "                                                },\n",
        "                                                \"Property\": \"Cumulative Deaths\",\n",
        "                                            },\n",
        "                                            \"Name\": \"Measures Table.Cumulative Deaths\",\n",
        "                                        },\n",
        "                                        {\n",
        "                                            \"Column\": {\n",
        "                                                \"Expression\": {\n",
        "                                                    \"SourceRef\": {\"Source\": \"d\"}\n",
        "                                                },\n",
        "                                                \"Property\": \"Case Creation Date\",\n",
        "                                            },\n",
        "                                            \"Name\": \"Dashboard Data RedCap.Case Creation Date\",\n",
        "                                        },\n",
        "                                        {\n",
        "                                            \"Measure\": {\n",
        "                                                \"Expression\": {\n",
        "                                                    \"SourceRef\": {\"Source\": \"m\"}\n",
        "                                                },\n",
        "                                                \"Property\": \"Cumulative Recoveries\",\n",
        "                                            },\n",
        "                                            \"Name\": \"Measures Table.Cumulative Recoveries\",\n",
        "                                        },\n",
        "                                    ],\n",
        "                                    \"Where\": [\n",
        "                                        {\n",
        "                                            \"Condition\": {\n",
        "                                                \"In\": {\n",
        "                                                    \"Expressions\": [\n",
        "                                                        {\n",
        "                                                            \"Column\": {\n",
        "                                                                \"Expression\": {\n",
        "                                                                    \"SourceRef\": {\n",
        "                                                                        \"Source\": \"d\"\n",
        "                                                                    }\n",
        "                                                                },\n",
        "                                                                \"Property\": \"Zip Code\",\n",
        "                                                            }\n",
        "                                                        }\n",
        "                                                    ],\n",
        "                                                    \"Values\": [\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'\"\n",
        "                                                                    + str(int(zip))\n",
        "                                                                    + \"'\"  # \"'79902'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ]\n",
        "                                                    ],\n",
        "                                                }\n",
        "                                            }\n",
        "                                        },\n",
        "                                        {\n",
        "                                            \"Condition\": {\n",
        "                                                \"In\": {\n",
        "                                                    \"Expressions\": [\n",
        "                                                        {\n",
        "                                                            \"Column\": {\n",
        "                                                                \"Expression\": {\n",
        "                                                                    \"SourceRef\": {\n",
        "                                                                        \"Source\": \"d\"\n",
        "                                                                    }\n",
        "                                                                },\n",
        "                                                                \"Property\": \"Zip Code\",\n",
        "                                                            }\n",
        "                                                        }\n",
        "                                                    ],\n",
        "                                                    \"Values\": [\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79835'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79836'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79838'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79849'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79853'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79901'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79902'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79903'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79904'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79905'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79907'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79911'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79912'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79915'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79922'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79924'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79925'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79927'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79928'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79929'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79930'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79932'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79934'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79935'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79936'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79938'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                        [\n",
        "                                                            {\n",
        "                                                                \"Literal\": {\n",
        "                                                                    \"Value\": \"'79821'\"\n",
        "                                                                }\n",
        "                                                            }\n",
        "                                                        ],\n",
        "                                                    ],\n",
        "                                                }\n",
        "                                            }\n",
        "                                        },\n",
        "                                    ],\n",
        "                                },\n",
        "                                \"Binding\": {\n",
        "                                    \"Primary\": {\n",
        "                                        \"Groupings\": [{\"Projections\": [0, 1, 2, 3]}]\n",
        "                                    },\n",
        "                                    \"DataReduction\": {\n",
        "                                        \"DataVolume\": 4,\n",
        "                                        \"Primary\": {\"BinnedLineSample\": {}},\n",
        "                                    },\n",
        "                                    \"Version\": 1,\n",
        "                                },\n",
        "                                \"ExecutionMetricsKind\": 1,\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                \"QueryId\": \"\",\n",
        "                \"ApplicationContext\": {\n",
        "                    \"DatasetId\": \"198d07f2-2ce6-402e-84f6-2fa0e46056b5\",\n",
        "                    \"Sources\": [{\"ReportId\": \"2f58c014-b3b1-4d53-9169-73a6a382c791\"}],\n",
        "                },\n",
        "            }\n",
        "        ],\n",
        "        \"cancelQueries\": [],\n",
        "        \"modelId\": 6406266,\n",
        "    }\n",
        "    print(payload)\n",
        "    # fasdfasdf\n",
        "    # Sending the data\n",
        "    section_data = requests.post(query_url, json=payload, headers=headers).json()\n",
        "    # Extracting the data series (date, positives, recoveries, deaths)\n",
        "    dataResponse = section_data[\"results\"][0][\"result\"][\"data\"][\"dsr\"][\"DS\"][0][\"PH\"][\n",
        "        0\n",
        "    ][\"DM0\"]\n",
        "\n",
        "    # Parsing the JSON response\n",
        "    import json\n",
        "\n",
        "    result = json.dumps(dataResponse)\n",
        "    json_object = json.loads(str(result))\n",
        "\n",
        "    # Converting the JSON response to a dataframe\n",
        "    df = pd.DataFrame.from_dict(json_object, orient=\"columns\")\n",
        "    # print(df)\n",
        "    del df[\"S\"]\n",
        "    # Traverse the C column to update it.\n",
        "    for index in range(0, df.C.shape[0]):\n",
        "        # If the length of df.C[index] == 3, this means that there's no deaths for this day\n",
        "        # and I need to update the list to insert a 0 (deaths) between\n",
        "        if len(df.C[index]) == 3:\n",
        "            # Adding a 0 at position 2\n",
        "            df.C[index].insert(2, 0)\n",
        "            # Converting from list to string\n",
        "            df.C[index] = \" \".join(map(str, df.C[index]))\n",
        "        elif len(df.C[index]) == 2:\n",
        "            # Adding a 0 at position 2\n",
        "            df.C[index].insert(2, 0)\n",
        "            df.C[index].insert(3, 0)\n",
        "            # Converting from list to string\n",
        "            df.C[index] = \" \".join(map(str, df.C[index]))\n",
        "        else:\n",
        "            # Converting from list to string\n",
        "            df.C[index] = \" \".join(map(str, df.C[index]))\n",
        "    # Replacing NaN values with 0\n",
        "    df.replace(np.nan, 0, inplace=True)\n",
        "    # Splitting the column C. Originally was a single column with three values.\n",
        "    df[[\"epoc_date\", \"positives\", \"deaths\", \"recoveries\"]] = df.C.str.split(\n",
        "        \" \", expand=True\n",
        "    )\n",
        "    # Removing the original column C\n",
        "    del df[\"C\"]\n",
        "    import datetime\n",
        "\n",
        "    # Changing the datatype of the columns\n",
        "    df[\"epoc_date\"] = df[\"epoc_date\"].astype(int)\n",
        "    df[\"positives\"] = df[\"positives\"].astype(float)\n",
        "    df[\"deaths\"] = df[\"deaths\"].astype(float)\n",
        "    df[\"recoveries\"] = df[\"recoveries\"].astype(float)\n",
        "\n",
        "    # Converting EPOCH time to human-readable format\n",
        "    df[\"date\"] = pd.to_datetime(df[\"epoc_date\"], unit=\"ms\")\n",
        "\n",
        "    from datetime import datetime\n",
        "\n",
        "    now = datetime.now()\n",
        "    # datetime_backup = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
        "    datetime_backup = now.strftime(\"%d_%m_%Y\")\n",
        "\n",
        "    df.to_pickle(\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/\"\n",
        "        + str(int(zip))\n",
        "        + \"_\"\n",
        "        + datetime_backup\n",
        "        + \".pkl\"\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a5P4-aj30r6"
      },
      "source": [
        "Fixing dates\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiP21pf99TW1"
      },
      "source": [
        "from pandas import Series\n",
        "\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "    lastValue = 0\n",
        "    diff = list()\n",
        "    diff.append(dataset[0])\n",
        "    for i in range(interval, len(dataset)):\n",
        "        # lastValue = dataset[i - 1]\n",
        "        if dataset[i - 1] > 0:\n",
        "            lastValue = dataset[i - 1]\n",
        "        # value = dataset[i] - dataset[i - interval]\n",
        "        value = dataset[i] - lastValue  # dataset[i - interval]\n",
        "        if dataset[i] > 0:\n",
        "            diff.append(value)\n",
        "        elif lastValue == 0:\n",
        "            diff.append(dataset[i])\n",
        "        elif dataset[i] == 0:\n",
        "            diff.append(dataset[i])\n",
        "    return Series(diff)\n",
        "\n",
        "\n",
        "# Generating the date range\n",
        "dates = pd.date_range(\"01-01-2020\", \"20-04-2021\", freq=\"D\")\n",
        "# Sufix for the file name\n",
        "dateSave = \"_23_04_2021\"\n",
        "# Reading the ZIP codes\n",
        "allZIPS = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/allZIPS_ELP.npy\",\n",
        "    allow_pickle=True,\n",
        ")\n",
        "for zip in allZIPS:\n",
        "    # print(zip)\n",
        "    df = pd.read_pickle(\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/\"\n",
        "        + str(int(zip))\n",
        "        + dateSave\n",
        "        + \".pkl\"\n",
        "    )\n",
        "    # print(df)\n",
        "    # Transform from cumulative to daily cases\n",
        "    # dif = difference(df['recoveries'],1)\n",
        "    df[\"positives\"] = difference(df[\"positives\"], 1)\n",
        "    df[\"recoveries\"] = difference(df[\"recoveries\"], 1)\n",
        "    df[\"deaths\"] = difference(df[\"deaths\"], 1)\n",
        "\n",
        "    # ====================================\n",
        "    # Adding missing dates with nan values\n",
        "    # ====================================\n",
        "\n",
        "    # Reasigning the column date as the new index\n",
        "    df.set_index(\"date\", inplace=True)\n",
        "    # Converting the new index to DatetimeIndex type\n",
        "    df.index = pd.DatetimeIndex(df.index)\n",
        "    # Adding the missing dates with nan values\n",
        "    df = df.reindex(dates, fill_value=np.nan)\n",
        "    # Removing the date column as index\n",
        "    df.reset_index(level=0, inplace=True)\n",
        "    # Renaming the new index column as date\n",
        "    df.rename({\"index\": \"date\"}, axis=1, inplace=True)\n",
        "    # Saving the fixed dataframe\n",
        "    df.to_pickle(\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/\"\n",
        "        + str(int(zip))\n",
        "        + dateSave\n",
        "        + \"_datesFixed.pkl\"\n",
        "    )\n",
        "\n",
        "# Merging zips 79911 and 79912\n",
        "zip79911 = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/79911\"\n",
        "    + dateSave\n",
        "    + \"_datesFixed.pkl\"\n",
        ")\n",
        "zip79912 = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/79912\"\n",
        "    + dateSave\n",
        "    + \"_datesFixed.pkl\"\n",
        ")\n",
        "zip79912[\"positives\"] = zip79912[\"positives\"] + zip79911[\"positives\"]\n",
        "zip79912[\"deaths\"] = zip79912[\"deaths\"] + zip79911[\"deaths\"]\n",
        "zip79912[\"recoveries\"] = zip79912[\"recoveries\"] + zip79911[\"recoveries\"]\n",
        "# print(zip79912)\n",
        "zip79912.to_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/79912\"\n",
        "    + dateSave\n",
        "    + \"_datesFixed.pkl\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOO-q9zVc1e"
      },
      "source": [
        "# SEIR Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN4Kix3SeyQi"
      },
      "source": [
        "Load ELP Population data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgMGkhfPFZYG"
      },
      "source": [
        "ELPCGB_population = gpd.read_file(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_population.shp\"\n",
        ")[[\"GEOID\", \"population\"]]\n",
        "print(ELPCGB_population[\"population\"].sum())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGH30y10fMQ3"
      },
      "source": [
        "Load OD matrix & ELP CGB dictionary\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7xGZvf9bxMd",
        "scrolled": true
      },
      "source": [
        "def getIndexFromELPCGBdictionary(df, cgb):\n",
        "    value = df[\"CGB\"].loc[df[\"index\"] == cgb]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "OD_matrices = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix.npy\"\n",
        ")\n",
        "elpcgb = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl\"\n",
        ")\n",
        "\n",
        "OD_matrices = np.where(OD_matrices == 0, 1, OD_matrices)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmvsA62u3IXk"
      },
      "source": [
        "Generating Outbound - Inbound data\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8hPD-KY91Ft"
      },
      "source": [
        "def getIndexFromELPCGBdictionary(df, cgb):\n",
        "    value = df[\"index\"].loc[df[\"CGB\"] == cgb]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "def getCBG(df, index):\n",
        "    value = df[\"CGB\"].loc[df[\"index\"] == index]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "ELPCGB_ZIP_DEMOGRAPHIC = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_ZIP_DEMOGRAPHIC.pkl\"\n",
        ")\n",
        "ELP_outbound = ELPCGB_ZIP_DEMOGRAPHIC[\n",
        "    [\n",
        "        \"STATEFP\",\n",
        "        \"COUNTYFP\",\n",
        "        \"TRACTCE\",\n",
        "        \"BLKGRPCE\",\n",
        "        \"GEOID\",\n",
        "        \"NAMELSAD\",\n",
        "        \"MTFCC\",\n",
        "        \"FUNCSTAT\",\n",
        "        \"ALAND\",\n",
        "        \"AWATER\",\n",
        "        \"INTPTLAT\",\n",
        "        \"INTPTLON\",\n",
        "        \"geometry\",\n",
        "        \"ZIP\",\n",
        "        \"B01001e1\",\n",
        "    ]\n",
        "].copy()\n",
        "ELP_inbound = ELPCGB_ZIP_DEMOGRAPHIC[\n",
        "    [\n",
        "        \"STATEFP\",\n",
        "        \"COUNTYFP\",\n",
        "        \"TRACTCE\",\n",
        "        \"BLKGRPCE\",\n",
        "        \"GEOID\",\n",
        "        \"NAMELSAD\",\n",
        "        \"MTFCC\",\n",
        "        \"FUNCSTAT\",\n",
        "        \"ALAND\",\n",
        "        \"AWATER\",\n",
        "        \"INTPTLAT\",\n",
        "        \"INTPTLON\",\n",
        "        \"geometry\",\n",
        "        \"ZIP\",\n",
        "        \"B01001e1\",\n",
        "    ]\n",
        "].copy()\n",
        "\n",
        "OD_matrices_copy = OD_matrices.copy()\n",
        "np.fill_diagonal(OD_matrices_copy[0], 0)\n",
        "\n",
        "outbound = OD_matrices_copy.sum(axis=2)\n",
        "inbound = OD_matrices_copy.sum(axis=1)\n",
        "print(outbound[0].shape)\n",
        "print(outbound[0][0])\n",
        "\n",
        "for time in range(0, outbound.shape[0]):\n",
        "    ELP_outbound[\"time\" + str(time)] = 0\n",
        "    for iCBG in range(0, outbound.shape[1]):\n",
        "        cgb = getCBG(elpcgb, iCBG)\n",
        "        ELP_outbound.loc[ELP_outbound.GEOID == cgb, \"time\" + str(time)] = outbound[\n",
        "            time\n",
        "        ][iCBG]\n",
        "        ELP_inbound.loc[ELP_inbound.GEOID == cgb, \"time\" + str(time)] = inbound[time][\n",
        "            iCBG\n",
        "        ]\n",
        "\n",
        "ELP_outbound.to_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELP_outbound.pkl\"\n",
        ")\n",
        "ELP_inbound.to_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELP_inbound.pkl\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eewTGKl25rr"
      },
      "source": [
        "Loading Outbound - Inbound data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqtAtxSgkST8"
      },
      "source": [
        "ELP_outbound = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELP_outbound.pkl\"\n",
        ")\n",
        "ELP_inbound = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELP_inbound.pkl\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77o8o-6n2pul"
      },
      "source": [
        "Creating Inbound - Outbound maps\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6uqF_gXr6kx"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def mobilityCBGgraph(df, time, figName, title):\n",
        "    plt.figure()\n",
        "    cmap = \"Oranges\"\n",
        "    plt.rcParams.update({\"font.size\": 32})\n",
        "    west, south, east, north = df.unary_union.bounds\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(20, 20))\n",
        "    fig.suptitle(title, fontsize=40)\n",
        "    df.plot(ax=ax, column=time, legend=False, cmap=cmap)\n",
        "\n",
        "    cbax = fig.add_axes([0.915, 0.175, 0.02, 0.7])\n",
        "\n",
        "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=0, vmax=2000))\n",
        "    # norm = plt.Normalize(vmin=min(df[time]), vmax=max(df[time])))\n",
        "\n",
        "    sm._A = []\n",
        "\n",
        "    # draw colormap into cbax\n",
        "\n",
        "    fig.colorbar(sm, cax=cbax, format=\"%d\")\n",
        "\n",
        "    ax.set_xlim(west, east)\n",
        "    ax.set_ylim(south, north)\n",
        "    # ax.axis('off')\n",
        "    ctx.add_basemap(ax, zoom=13, crs=4326)\n",
        "    # plt.show()\n",
        "    fig.savefig(\n",
        "        \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/Mobility/\" + figName\n",
        "    )\n",
        "    plt.close(\"all\")\n",
        "\n",
        "\n",
        "dateRange = (\n",
        "    pd.date_range(\"2020-01\", \"2020-10-25\", freq=\"D\").strftime(\"%Y/%m/%d\").tolist()\n",
        ")\n",
        "print(len(dateRange))\n",
        "for i in range(0, 299):\n",
        "    # for i in range(0,1):\n",
        "    datetime_str = dateRange[i] + \" 00:00:00\"\n",
        "    datetime_object = datetime.strptime(datetime_str, \"%Y/%m/%d %H:%M:%S\")\n",
        "    date = datetime_object.strftime(\"%A, %B %d, %Y\")\n",
        "    title = \"Outbound | \" + str(date)\n",
        "    mobilityCBGgraph(ELP_outbound, \"time\" + str(i), \"outbound/outbound\" + str(i), title)\n",
        "    title = \"Inbound | \" + str(date)\n",
        "    mobilityCBGgraph(ELP_inbound, \"time\" + str(i), \"inbound/inbound\" + str(i), title)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GHE1tjofeci"
      },
      "source": [
        "Loading Population Matrix\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iefp7HwVbxMf"
      },
      "source": [
        "np.set_printoptions(suppress=True, precision=3)\n",
        "pop = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/PopulationMatrixACS2012_2016.npy\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm_C7_OyR-7G"
      },
      "source": [
        "V2.1 - ELP Strong (COVID data) + SafeGraph (Mobility data)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP82BZKEUQQL"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "import os, sys\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "mpld3.disable_notebook()\n",
        "\n",
        "# Function to retrieve the ID of a CBG\n",
        "def getIndex(df, cgb):\n",
        "    value = df[\"index\"].loc[df[\"CGB\"] == cgb]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "# Function to retrieve the CBG from the ID\n",
        "def getCBG(df, index):\n",
        "    value = df[\"CGB\"].loc[df[\"index\"] == index]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# Loading COVID data\n",
        "# ===========================================================\n",
        "# TODO: rows/columns meaning\n",
        "elp_ZIP_POP_COVID = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/elp_ZIP_POP_COVID_V2.pkl\"\n",
        ")\n",
        "elp_ZIP_POP_COVID.fillna(0, inplace=True)\n",
        "# ===========================================================\n",
        "\n",
        "# ===========================================================\n",
        "# Load the Population Matrix\n",
        "# ===========================================================\n",
        "population = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/PopulationMatrixACS2012_2016.npy\"\n",
        ")\n",
        "# ===========================================================\n",
        "\n",
        "# ===========================================================\n",
        "# Load the ELP CBG dictionary\n",
        "# ===========================================================\n",
        "ELP_CGB_dictionary = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl\"\n",
        ")\n",
        "# ===========================================================\n",
        "\n",
        "# ===========================================================\n",
        "# Load the O-D matrix\n",
        "# ===========================================================\n",
        "# OD_matrices = np.load(\"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix.npy\")\n",
        "OD_matrices = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODMatrixBaseLine-2020-01-01_2021-12-31.npy\"\n",
        ")\n",
        "# Replace 0's with 1's (with 0's occur an error dividing by 0)\n",
        "OD_matrices = np.where(OD_matrices == 0, 1, OD_matrices)\n",
        "OD_matrices = OD_matrices.astype(np.float64)\n",
        "# print(\"OD_matrices: \",OD_matrices.shape)\n",
        "# ===========================================================\n",
        "\n",
        "print(\"Total Population: \" + str(np.sum(population[0])))\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# Specify the number of infected people in each CBG\n",
        "# ===========================================================\n",
        "initialDate = \"2020-04-12\"\n",
        "\n",
        "\n",
        "initialInd = []\n",
        "initial = []\n",
        "CBG_date = elp_ZIP_POP_COVID[[\"GEOID\", initialDate]]\n",
        "# print(CBG_date.head())\n",
        "for index, row in CBG_date.iterrows():\n",
        "    # Initial CGB indices where people are infected\n",
        "    initialInd.append(getIndex(ELP_CGB_dictionary, row[\"GEOID\"]))\n",
        "    # Number of infected people in each CGB\n",
        "    initial.append(row[initialDate])\n",
        "\n",
        "initialCases = np.zeros(CBG_date.shape[0])\n",
        "initialCases[initialInd] = initial\n",
        "\n",
        "# Max number of days that I can simulate\n",
        "MAX_DAYS = 300\n",
        "# Number of days for the simulation\n",
        "simulationDays = []\n",
        "dateRange = (\n",
        "    pd.date_range(\"2020-01\", \"2020-10-25\", freq=\"D\").strftime(\"%Y-%m-%d\").tolist()\n",
        ")\n",
        "# index of the initial day\n",
        "nStartDay = dateRange.index(initialDate)\n",
        "\n",
        "# ===========================================================\n",
        "# Number of days of the simulations\n",
        "# ===========================================================\n",
        "numberDaysSimulation = MAX_DAYS - nStartDay\n",
        "simulationDays.append(nStartDay)\n",
        "simulationDays.append(numberDaysSimulation)\n",
        "\n",
        "# ============================================================\n",
        "# SEIR model\n",
        "# ============================================================\n",
        "def SEIR(\n",
        "    y,\n",
        "    t,\n",
        "    N,\n",
        "    beta,\n",
        "    gamma,\n",
        "    delta,\n",
        "    mobilityRestriction,\n",
        "    outflowS,\n",
        "    outflowE,\n",
        "    outflowI,\n",
        "    outflowR,\n",
        "    inflowS,\n",
        "    inflowE,\n",
        "    inflowI,\n",
        "    inflowR,\n",
        "):\n",
        "    S, E, I, R = y\n",
        "\n",
        "    rS = S\n",
        "    rE = E\n",
        "    rI = I\n",
        "    rR = R\n",
        "\n",
        "    dSdt = -beta * rI * (rS / N)\n",
        "    dEdt = beta * rI * (rS / N) - (delta * rE)\n",
        "    dIdt = (delta * rE) - (gamma * rI)\n",
        "    dRdt = gamma * rI\n",
        "\n",
        "    return dSdt, dEdt, dIdt, dRdt\n",
        "\n",
        "\n",
        "def SEIRmobility(\n",
        "    y,\n",
        "    t,\n",
        "    N,\n",
        "    beta,\n",
        "    gamma,\n",
        "    delta,\n",
        "    mobilityRestriction,\n",
        "    outflowS,\n",
        "    outflowE,\n",
        "    outflowI,\n",
        "    outflowR,\n",
        "    inflowS,\n",
        "    inflowE,\n",
        "    inflowI,\n",
        "    inflowR,\n",
        "):\n",
        "    S, E, I, R = y\n",
        "\n",
        "    rS = (S - outflowS + inflowS) * mobilityRestriction\n",
        "    rE = (E - outflowE + inflowE) * mobilityRestriction\n",
        "    rI = (I - outflowI + inflowI) * mobilityRestriction\n",
        "    rR = (R - outflowR + inflowR) * mobilityRestriction\n",
        "\n",
        "    dSdt = -beta * rI * (rS / N)\n",
        "    dEdt = beta * rI * (rS / N) - (delta * rE)\n",
        "    dIdt = (delta * rE) - (gamma * rI)\n",
        "    dRdt = gamma * rI\n",
        "\n",
        "    return dSdt, dEdt, dIdt, dRdt\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Initial values of each CBG, Susceptible, Infected, and Recovered\n",
        "# ============================================================\n",
        "\n",
        "numberCBG = population.shape[1]\n",
        "\n",
        "population = population[0]\n",
        "aE = np.zeros(numberCBG, dtype=float)\n",
        "aI = initialCases\n",
        "aR = np.zeros(numberCBG, dtype=float)\n",
        "aS = np.array(population - (aE + aI + aR), np.float)\n",
        "population = aS + aE + aI + aR\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Initial conditions\n",
        "# ============================================================\n",
        "S0, E0, I0, R0 = aS, aE, aI, aR  # initial conditions: one infected, rest susceptible\n",
        "points = 300\n",
        "t = np.linspace(0, points - 1, points)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Mobility\n",
        "# ============================================================\n",
        "# Generate random mobility data\n",
        "mobility = OD_matrices  # np.random.randint(1,100,(points,len(aS),len(aS)))\n",
        "\n",
        "# Fill main diagonal with 0s\n",
        "for tm in range(0, mobility.shape[0]):\n",
        "    np.fill_diagonal(mobility[tm], 0)\n",
        "\n",
        "# Create a copy of the mobility data\n",
        "mobilityNorm = mobility.copy()\n",
        "\n",
        "# Convert the population vector from row to column in order to normalize the mobility\n",
        "pop = population.reshape(len(population), 1)\n",
        "\n",
        "# Normalize the mobility dividing it by the population of each CBG\n",
        "mobilityNorm = mobilityNorm / pop\n",
        "\n",
        "# ============================================================\n",
        "# Record initial conditions\n",
        "# ============================================================\n",
        "# Population\n",
        "N = np.zeros((len(t), len(aS))).astype(np.float64)\n",
        "\n",
        "N[0] = aS + aE + aI + aR\n",
        "populationCBGs = N.copy()\n",
        "\n",
        "# ============================================================\n",
        "# Matrix to store the results: timesteps, 4 (SEIR), N.shape (# of CGB)\n",
        "# ============================================================\n",
        "resultsSEIR = np.zeros((len(t), 4, N.shape[1]))\n",
        "resultsSEIR[0][0] = S0\n",
        "resultsSEIR[0][1] = E0\n",
        "resultsSEIR[0][2] = I0\n",
        "resultsSEIR[0][3] = R0\n",
        "\n",
        "# ============================================================\n",
        "# Vectors to sum the CBG and to get the regional results\n",
        "# ============================================================\n",
        "totalS = np.zeros((len(t))).astype(np.float64)\n",
        "totalE = np.zeros((len(t))).astype(np.float64)\n",
        "totalI = np.zeros((len(t))).astype(np.float64)\n",
        "totalR = np.zeros((len(t))).astype(np.float64)\n",
        "\n",
        "totalS[0] = np.sum(aS)\n",
        "totalE[0] = np.sum(aE)\n",
        "totalI[0] = np.sum(aI)\n",
        "totalR[0] = np.sum(aR)\n",
        "\n",
        "# ============================================================\n",
        "# ELP Strong R0\n",
        "# ============================================================\n",
        "ELPStrong_R0 = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELPStrong_R0.pkl\"\n",
        ")\n",
        "R0 = ELPStrong_R0[\"R0\"].values\n",
        "\n",
        "# print(mobilityNorm)\n",
        "# ============================================================\n",
        "# Running the model\n",
        "# ============================================================\n",
        "# for cbg in range(0,N.shape[1]):\n",
        "print(\"*\" * 40)\n",
        "for timeStep in range(1, len(t)):\n",
        "    for cbg in range(0, N.shape[1]):\n",
        "\n",
        "        # ============================================================\n",
        "        # Initial parameters\n",
        "        # ============================================================\n",
        "        D = 10.0  # infections lasts four days\n",
        "        gamma = 1.0 / D\n",
        "        delta = 1.0 / 5.6  # incubation period of five days\n",
        "        R_0 = R0[timeStep - 1]\n",
        "        beta = float(R_0) * gamma\n",
        "\n",
        "        # popMob = N[0][cbg]\n",
        "        SEIRsum = (\n",
        "            resultsSEIR[timeStep - 1][0][cbg]\n",
        "            + resultsSEIR[timeStep - 1][1][cbg]\n",
        "            + resultsSEIR[timeStep - 1][2][cbg]\n",
        "            + resultsSEIR[timeStep - 1][3][cbg]\n",
        "        )\n",
        "\n",
        "        y0 = (\n",
        "            resultsSEIR[timeStep - 1][0][cbg],\n",
        "            resultsSEIR[timeStep - 1][1][cbg],\n",
        "            resultsSEIR[timeStep - 1][2][cbg],\n",
        "            resultsSEIR[timeStep - 1][3][cbg],\n",
        "        )\n",
        "        tspan = [t[timeStep - 1], t[timeStep]]\n",
        "\n",
        "        # Compute the outflow\n",
        "        outflowS = np.sum(\n",
        "            mobilityNorm[timeStep - 1][cbg] * resultsSEIR[timeStep - 1][0][cbg]\n",
        "        )\n",
        "        outflowE = np.sum(\n",
        "            mobilityNorm[timeStep - 1][cbg] * resultsSEIR[timeStep - 1][1][cbg]\n",
        "        )\n",
        "        outflowI = np.sum(\n",
        "            mobilityNorm[timeStep - 1][cbg] * resultsSEIR[timeStep - 1][2][cbg]\n",
        "        )\n",
        "        outflowR = np.sum(\n",
        "            mobilityNorm[timeStep - 1][cbg] * resultsSEIR[timeStep - 1][3][cbg]\n",
        "        )\n",
        "\n",
        "        inflowS = np.sum(\n",
        "            (mobilityNorm[timeStep - 1][:, [cbg]].T) * resultsSEIR[timeStep - 1][0][cbg]\n",
        "        )\n",
        "        inflowE = np.sum(\n",
        "            (mobilityNorm[timeStep - 1][:, [cbg]].T) * resultsSEIR[timeStep - 1][1][cbg]\n",
        "        )\n",
        "        inflowI = np.sum(\n",
        "            (mobilityNorm[timeStep - 1][:, [cbg]].T) * resultsSEIR[timeStep - 1][2][cbg]\n",
        "        )\n",
        "        inflowR = np.sum(\n",
        "            (mobilityNorm[timeStep - 1][:, [cbg]].T) * resultsSEIR[timeStep - 1][3][cbg]\n",
        "        )\n",
        "\n",
        "        popMob = (\n",
        "            N[0][cbg]\n",
        "            - (outflowS + outflowE + outflowI + outflowR)\n",
        "            + (inflowS + inflowE + inflowI + inflowR)\n",
        "        )\n",
        "\n",
        "        # Integrate the SIR ODEs\n",
        "        (z, d) = odeint(\n",
        "            SEIRmobility,\n",
        "            y0,\n",
        "            tspan,\n",
        "            args=(\n",
        "                popMob,\n",
        "                beta,\n",
        "                gamma,\n",
        "                delta,\n",
        "                1.0,\n",
        "                outflowS,\n",
        "                outflowE,\n",
        "                outflowI,\n",
        "                outflowR,\n",
        "                inflowS,\n",
        "                inflowE,\n",
        "                inflowI,\n",
        "                inflowR,\n",
        "            ),\n",
        "            full_output=1,\n",
        "        )\n",
        "        # print(d)\n",
        "        # print('-'*10)\n",
        "        # Save the new SIR results\n",
        "        resultsSEIR[timeStep][0][cbg] = z[1][0]\n",
        "        resultsSEIR[timeStep][1][cbg] = z[1][1]\n",
        "        resultsSEIR[timeStep][2][cbg] = z[1][2]\n",
        "        resultsSEIR[timeStep][3][cbg] = z[1][3]\n",
        "\n",
        "        # Sum the results of each CBG to get the regional results\n",
        "        totalS[timeStep] = totalS[timeStep] + z[1][0]\n",
        "        totalE[timeStep] = totalE[timeStep] + z[1][1]\n",
        "        totalI[timeStep] = totalI[timeStep] + z[1][2]\n",
        "        totalR[timeStep] = totalR[timeStep] + z[1][3]\n",
        "\n",
        "        # Updating the initial condition\n",
        "        y0 = (\n",
        "            resultsSEIR[timeStep][0][cbg],\n",
        "            resultsSEIR[timeStep][1][cbg],\n",
        "            resultsSEIR[timeStep][2][cbg],\n",
        "            resultsSEIR[timeStep][3][cbg],\n",
        "        )\n",
        "\n",
        "\n",
        "viz_test = plt\n",
        "\n",
        "viz_test.figure(figsize=(20, 10))\n",
        "\n",
        "SMALL_SIZE = 20\n",
        "MEDIUM_SIZE = 20\n",
        "BIGGER_SIZE = 60\n",
        "\n",
        "viz_test.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
        "viz_test.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
        "viz_test.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "viz_test.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
        "viz_test.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "# x_pos = [i for i, _ in enumerate(outflowMatrix2019[0])]\n",
        "\n",
        "viz_test.plot(t, totalS, \"b-\", label=\"Susceptible\")\n",
        "viz_test.plot(t, totalE, \"m-\", label=\"Exposed\")\n",
        "viz_test.plot(t, totalI, \"r-\", label=\"Infected\")\n",
        "viz_test.plot(t, totalR, \"g--\", label=\"Recovered\")\n",
        "viz_test.plot(t, totalS + totalE + totalI + totalR, \"k--\", label=\"Total\")\n",
        "viz_test.ylabel(\"Population\")\n",
        "viz_test.xlabel(\"time\")\n",
        "viz_test.legend(loc=\"best\")\n",
        "viz_test.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP78Y5DZjchE"
      },
      "source": [
        "totalS = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/totalS.npy\"\n",
        ").T\n",
        "totalE = np.load(\"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/totalE.npy\")\n",
        "totalI = np.load(\"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/totalI.npy\")\n",
        "totalR = np.load(\"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/totalR.npy\")\n",
        "\n",
        "\n",
        "totalSm = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/totalSm.npy\"\n",
        ")\n",
        "totalEm = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/totalEm.npy\"\n",
        ")\n",
        "totalIm = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/totalIm.npy\"\n",
        ")\n",
        "totalRm = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/totalRm.npy\"\n",
        ")\n",
        "\n",
        "# t = totalI - totalIm\n",
        "\n",
        "print(totalS.shape)\n",
        "\n",
        "viz_test = plt\n",
        "\n",
        "viz_test.figure(figsize=(20, 10))\n",
        "\n",
        "SMALL_SIZE = 20\n",
        "MEDIUM_SIZE = 20\n",
        "BIGGER_SIZE = 60\n",
        "\n",
        "viz_test.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
        "viz_test.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
        "viz_test.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "viz_test.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
        "viz_test.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "viz_test.plot(t, totalI, \"r-\", label=\"Infected\")\n",
        "viz_test.plot(t, totalIm, \"r--\", label=\"Infected M\")\n",
        "\n",
        "viz_test.plot(t, totalIm - totalI, \"b--\", label=\"Infected M\")\n",
        "\n",
        "viz_test.plot(t, totalS + totalE + totalI + totalR, \"k--\", label=\"Total\")\n",
        "viz_test.ylabel(\"Population\")\n",
        "viz_test.xlabel(\"time\")\n",
        "viz_test.legend(loc=\"best\")\n",
        "viz_test.show()\n",
        "\n",
        "\n",
        "print(totalIm - totalI)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLB2MdFO8dYb"
      },
      "source": [
        "OD_matrices = np.load(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODMatrixBaseLine-2020-01-01_2021-12-31.npy\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnAlcriQK8wb"
      },
      "source": [
        "Fit model to actual data SEIRD - Dynamic R0\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4248BAQTK8N1"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib import dates\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from datetime import datetime\n",
        "from lmfit import minimize, Parameters, Parameter, report_fit\n",
        "\n",
        "# !pip install numdifftools\n",
        "\n",
        "# ******************************************************************************\n",
        "# LOAD ELP STRONG R0 VALUES\n",
        "# ******************************************************************************\n",
        "ELPStrong_R0 = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELPStrong_R0.pkl\"\n",
        ")\n",
        "print(ELPStrong_R0)\n",
        "# dd\n",
        "ELP_R0 = np.array(ELPStrong_R0[\"R0\"].values, dtype=float)\n",
        "\n",
        "# ******************************************************************************\n",
        "# LOAD ELP STRONG COVID DATA\n",
        "# ******************************************************************************\n",
        "elp_ZIP_POP_COVID = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/elp_ZIP_POP_COVID_V2.pkl\"\n",
        ")\n",
        "elp_ZIP_POP_COVID.fillna(0, inplace=True)\n",
        "dfDates = elp_ZIP_POP_COVID.iloc[:, 87:-1]\n",
        "elpCovidCurve = dfDates.sum()\n",
        "\n",
        "# ===========================================================\n",
        "# Get day of year using a date\n",
        "# ===========================================================\n",
        "from datetime import datetime, date\n",
        "\n",
        "\n",
        "def getDayNumberOfTheYear(year, month, day):\n",
        "    return date(year, month, day).timetuple().tm_yday - 1\n",
        "\n",
        "\n",
        "# WAVE 1: 2020-04-06 - 2020-09-17\n",
        "wave = 1\n",
        "ELPStrong_wave = elpCovidCurve[15:180]\n",
        "dateStart = \"2020-04-06\"\n",
        "dateEnd = \"2020-09-17\"\n",
        "index = getDayNumberOfTheYear(2020, 4, 6)\n",
        "R_0_change = np.array(\n",
        "    ELPStrong_R0[\"R0\"]\n",
        "    .loc[(ELPStrong_R0[\"date\"] >= \"2020-04-12\") & (ELPStrong_R0[\"date\"] <= dateEnd)]\n",
        "    .values,\n",
        "    dtype=float,\n",
        ")\n",
        "k = np.mean(np.abs(np.diff(R_0_change)))\n",
        "R_0_start = float(ELPStrong_R0[\"R0\"].loc[ELPStrong_R0[\"date\"] == \"2020-04-12\"].values)\n",
        "R_0_end = float(ELPStrong_R0[\"R0\"].loc[ELPStrong_R0[\"date\"] == dateEnd].values)\n",
        "x0 = np.argmax(ELPStrong_wave)\n",
        "\n",
        "elpCovidCurve = ELPStrong_wave\n",
        "\n",
        "# ******************************************************************************\n",
        "# LOAD ELP STRONG MORTALITY RATE VALUES\n",
        "# ******************************************************************************\n",
        "dfFatalityRate = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/dfFatalityRate.pkl\"\n",
        ")\n",
        "mRate = dfFatalityRate.loc[\n",
        "    (dfFatalityRate.index >= dateStart) & (dfFatalityRate.index <= dateEnd)\n",
        "].values\n",
        "mRate = np.array(mRate, dtype=float).mean()\n",
        "\n",
        "\n",
        "# ******************************************************************************\n",
        "# SEIRD MODEL\n",
        "# ******************************************************************************\n",
        "def SEIRmobility(y, t, N, ps):\n",
        "\n",
        "    # N: total population\n",
        "    # S(t): number of people susceptible on day t\n",
        "    # E(t): number of people exposed on day t\n",
        "    # I(t): number of people infected on day t\n",
        "    # R(t): number of people recovered on day t\n",
        "    # β (beta): expected amount of people an infected person infects per day\n",
        "    # D: number of days an infected person has and can spread the disease\n",
        "    # γ (gamma): the proportion of infected recovering per day (γ = 1/D)\n",
        "    # R₀: the total number of people an infected person infects (R₀ = β / γ)\n",
        "    # δ (delta): length of incubation period\n",
        "    # α: fatality rate\n",
        "    # ρ: rate at which people die (= 1/days from infected until death)\n",
        "\n",
        "    S, E, I, R, D = y\n",
        "    beta_i = betaF(t)\n",
        "    gamma = ps[\"gamma\"].value\n",
        "    delta = ps[\"delta\"].value\n",
        "    alpha = ps[\"alpha\"].value\n",
        "    rho = ps[\"rho\"].value\n",
        "\n",
        "    beta = beta_i\n",
        "\n",
        "    rS = S\n",
        "    rE = E\n",
        "    rI = I\n",
        "    rR = R\n",
        "\n",
        "    dSdt = -beta * rI * (rS / N)\n",
        "    dEdt = beta * rI * (rS / N) - (delta * rE)\n",
        "    dIdt = delta * rE - ((1 - alpha) * gamma * rI) - (alpha * rho * rI)\n",
        "    dRdt = (1 - alpha) * gamma * rI\n",
        "    dDdt = alpha * rho * rI\n",
        "\n",
        "    return dSdt, dEdt, dIdt, dRdt, dDdt\n",
        "\n",
        "\n",
        "def odesol(y, t, N, ps):\n",
        "    I0 = ps[\"i0\"].value\n",
        "    y0 = S0, E0, I0, R0, D0\n",
        "    x = odeint(SEIRmobility, y0, t, args=(N, ps))\n",
        "    return x\n",
        "\n",
        "\n",
        "def residual(ps, ts, data):\n",
        "    model = pd.DataFrame(odesol(y0, t, N, ps), columns=[\"S\", \"E\", \"I\", \"R\", \"D\"])\n",
        "    return (model[\"I\"].values - data).ravel()\n",
        "\n",
        "\n",
        "bruteForceGamma = np.empty([0, 7], dtype=float)\n",
        "for value in np.arange(0, 1, 1):\n",
        "    # for value in np.arange(1, 9, 0.1):\n",
        "    # ******************************************************************************\n",
        "    # SEIR MODEL - PARAMETERS\n",
        "\n",
        "    # β (beta): expected amount of people an infected person infects per day\n",
        "    # D: number of days an infected person has and can spread the disease\n",
        "    # γ (gamma): the proportion of infected recovering per day (γ = 1/D)\n",
        "    # R₀: the total number of people an infected person infects (R₀ = β / γ)\n",
        "    # δ (delta): length of incubation period\n",
        "    # α (alpha): fatality rate\n",
        "    # ρ (rho): rate at which people die (= 1/days from infected until death)\n",
        "\n",
        "    # ******************************************************************************\n",
        "    # Total population, N.\n",
        "    N = 833592.0\n",
        "\n",
        "    D = 4.0\n",
        "    gamma = 1.0 / D\n",
        "\n",
        "    beta = float(R_0_start) * gamma\n",
        "\n",
        "    IncubationPeriod = 6.9\n",
        "    delta = 1.0 / IncubationPeriod\n",
        "\n",
        "    alpha = mRate\n",
        "    rho = 1 / 9.0\n",
        "\n",
        "    def logistic_R_0(t):\n",
        "        return (R_0_start - R_0_end) / (1 + np.exp(-k * (-t + x0))) + R_0_end\n",
        "\n",
        "    def betaF(t):\n",
        "        return logistic_R_0(t) * gamma\n",
        "\n",
        "    # The total number of people an infected person infects (R₀ = β / γ)\n",
        "    # Simply explained, R0 represents the average number of people infected by one infectious individual.\n",
        "    # If R0 is larger than 1, the number of infected people will likely increase exponentially, and an epidemic could ensue.\n",
        "    # If R0 is less than 1, the outbreak is likely to peter out on its own.\n",
        "    # R0 alone cannot definitively forecast an outbreak, but “it’s like an early warning system, in a lot of ways,\n",
        "    # for the possibility of an epidemic or pandemic,”\n",
        "\n",
        "    # ******************************************************************************\n",
        "    # COMPUTING THE INITIAL VALUES\n",
        "    # ******************************************************************************\n",
        "    I0, R0, E0, D0 = elpCovidCurve.min(), 0, 0, 0\n",
        "    # I0, R0, E0 = elpCovidCurve[0], 0, 0\n",
        "    # Everyone else, S0, is susceptible to infection initially.\n",
        "    S0 = N - I0 - R0\n",
        "    # Initial conditions vector\n",
        "    # y0 = S0, I0, R0\n",
        "    y0 = S0, E0, I0, R0, D0\n",
        "\n",
        "    # ******************************************************************************\n",
        "    # CREATING THE t VECTOR\n",
        "    # ******************************************************************************\n",
        "    t = np.linspace(0, elpCovidCurve.shape[0] - 1, elpCovidCurve.shape[0])\n",
        "\n",
        "    # ******************************************************************************\n",
        "    # LMFIT - SET PARAMETERS\n",
        "    # ******************************************************************************\n",
        "    params = Parameters()\n",
        "    params.add(\n",
        "        \"i0\", elpCovidCurve[0]\n",
        "    )  # , min=elpCovidCurve.min())#, max=elpCovidCurve.max())#, brute_step=300)#elpCovidCurve.max())#elpCovidCurve[10:-1].mean())#343.5)#elpCovidCurve[0:7].mean())#327.257843)#436)#, min=elpCovidCurve.min(), max=elpCovidCurve.max())\n",
        "    params.add(\"beta_i\", value=beta, min=0.01, max=beta)  # , brute_step=0.1)\n",
        "    params.add(\"gamma\", value=gamma, min=0.01, max=gamma)  # , brute_step=0.1)\n",
        "    params.add(\"delta\", value=delta, min=0.001, max=delta)  # , brute_step=0.1)\n",
        "    params.add(\"alpha\", value=alpha, min=0.001, max=alpha)  # , brute_step=0.1)\n",
        "    params.add(\"rho\", value=rho, min=0.01, max=rho)  # , brute_step=0.1)\n",
        "\n",
        "    # ******************************************************************************\n",
        "    # GET ACTUAL DATA FROM ELP STRONG\n",
        "    # ******************************************************************************\n",
        "    # real data\n",
        "    data = elpCovidCurve.values  # dfr['totale_positivi'].values\n",
        "\n",
        "    # ******************************************************************************\n",
        "    # LMFIT - FIT MODEL AND FIND PREDICTED VALUES\n",
        "    # ******************************************************************************\n",
        "    # fit model and find predicted values\n",
        "    result = minimize(residual, params, args=(t, data), method=\"leastsq\")\n",
        "    final = data + result.residual.reshape(data.shape)\n",
        "    print(\"R0: \", value)\n",
        "    report_fit(result)\n",
        "    print(\"=\" * 40)\n",
        "    # dd\n",
        "    bruteForceGamma = np.insert(\n",
        "        bruteForceGamma,\n",
        "        0,\n",
        "        [\n",
        "            value,\n",
        "            result.redchi,\n",
        "            result.last_internal_values[0],\n",
        "            result.last_internal_values[0],\n",
        "            result.last_internal_values[0],\n",
        "            result.last_internal_values[0],\n",
        "            result.last_internal_values[0],\n",
        "        ],\n",
        "        axis=0,\n",
        "    )\n",
        "\n",
        "# ******************************************************************************\n",
        "# PLOT DATA AND FITTED CURVES\n",
        "# ******************************************************************************\n",
        "# plot data and fitted curves\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.plot(t, data, \"-\", c=\"silver\", label=\"COVID-19 Data\")\n",
        "plt.plot(\n",
        "    t,\n",
        "    final,\n",
        "    \"--\",\n",
        "    linewidth=2,\n",
        "    c=\"red\",\n",
        "    label=\"Best Fit ODE - SEIR\" + \" - MAX: \" + str(final.max()),\n",
        ")\n",
        "plt.xlabel(\"Days\")\n",
        "plt.ylabel(\"Infected\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YWTrPkNtst6"
      },
      "source": [
        "# SEIR+M Fitted\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5MS2sZuIalf"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "import os, sys\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "mpld3.disable_notebook()\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "np.set_printoptions(suppress=True)\n",
        "# ===========================================================\n",
        "# Get day of year using a date\n",
        "# ===========================================================\n",
        "from datetime import datetime, date\n",
        "\n",
        "\n",
        "def getDayNumberOfTheYear(year, month, day):\n",
        "    return date(year, month, day).timetuple().tm_yday - 1\n",
        "\n",
        "\n",
        "# Function to retrieve the ID of a CBG\n",
        "def getIndex(df, cgb):\n",
        "    value = df[\"index\"].loc[df[\"CGB\"] == cgb]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "# Function to retrieve the CBG from the ID\n",
        "def getCBG(df, index):\n",
        "    value = df[\"CGB\"].loc[df[\"index\"] == index]\n",
        "    return value.values[0]\n",
        "\n",
        "\n",
        "def SEIRmobility(\n",
        "    y,\n",
        "    t,\n",
        "    N,\n",
        "    beta,\n",
        "    gamma,\n",
        "    delta,\n",
        "    tau,\n",
        "    mobilityRestriction,\n",
        "    outflowS,\n",
        "    outflowE,\n",
        "    outflowI,\n",
        "    outflowR,\n",
        "    inflowS,\n",
        "    inflowE,\n",
        "    inflowI,\n",
        "    inflowR,\n",
        "):\n",
        "\n",
        "    # N: total population\n",
        "    # S(t): number of people susceptible on day t\n",
        "    # E(t): number of people exposed on day t\n",
        "    # I(t): number of people infected on day t\n",
        "    # R(t): number of people recovered on day t\n",
        "    # β (beta): expected amount of people an infected person infects per day\n",
        "    # D: number of days an infected person has and can spread the disease\n",
        "    # γ (gamma): the proportion of infected recovering per day (γ = 1/D)\n",
        "    # R₀: the total number of people an infected person infects (R₀ = β / γ)\n",
        "    # δ (delta): length of incubation period\n",
        "    # α: fatality rate\n",
        "    # ρ: rate at which people die (= 1/days from infected until death)\n",
        "\n",
        "    S, E, I, R = y\n",
        "\n",
        "    try:\n",
        "        beta_i = beta\n",
        "        tau = tau\n",
        "        gamma = gamma\n",
        "        delta = delta\n",
        "    except:\n",
        "        print(\"--\")\n",
        "\n",
        "    beta = (beta_i * (1.1 - tau * t)) * (mobilityRestriction)\n",
        "\n",
        "    rS = S - outflowS * mobilityRestriction + inflowS * mobilityRestriction\n",
        "    rE = E - outflowE * mobilityRestriction + inflowE * mobilityRestriction\n",
        "    rI = I - outflowI * mobilityRestriction + inflowI * mobilityRestriction\n",
        "    rR = R - outflowR * mobilityRestriction + inflowR * mobilityRestriction\n",
        "\n",
        "    dSdt = -beta * rI * (rS / N)\n",
        "    dEdt = beta * rI * (rS / N) - (delta * rE)\n",
        "    dIdt = (delta * rE) - (gamma * rI)\n",
        "    dRdt = gamma * rI\n",
        "\n",
        "    return dSdt, dEdt, dIdt, dRdt\n",
        "\n",
        "\n",
        "# ===========================================================\n",
        "# Load COVID cases\n",
        "# ===========================================================\n",
        "elp_ZIP_POP_COVID = pd.read_pickle(\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/elp_ZIP_POP_COVID_V2.pkl\"\n",
        ")\n",
        "elp_ZIP_POP_COVID.fillna(0, inplace=True)\n",
        "dfDates = elp_ZIP_POP_COVID.iloc[:, 87:-1]\n",
        "elpCovidCurve = dfDates.sum()\n",
        "\n",
        "# ===========================================================\n",
        "# Define COVID waves\n",
        "# ===========================================================\n",
        "wave = 2\n",
        "ELPStrong_wave = elpCovidCurve[180:280]\n",
        "dateStart = \"2020-09-18\"\n",
        "dateEnd = \"2020-12-26\"\n",
        "indexStart = getDayNumberOfTheYear(2020, 9, 18)\n",
        "elpCovidCurve = ELPStrong_wave\n",
        "\n",
        "\n",
        "mobilityRestrictionExperiment = 100.0\n",
        "mobRestrictionPercentage = 0.0\n",
        "daysWindow = 0\n",
        "\n",
        "\n",
        "mre = np.array([50.0])\n",
        "dw = np.array([8])\n",
        "\n",
        "for mobilityRestrictionExperiment in mre:\n",
        "    for daysWindow in dw:\n",
        "        # ===========================================================\n",
        "        # MOBILITY CHANGE\n",
        "        # ===========================================================\n",
        "        from datetime import datetime, date\n",
        "        import datetime\n",
        "        from datetime import date\n",
        "\n",
        "        day_of_year = date(2020, 2, 29).timetuple().tm_yday\n",
        "\n",
        "        # WAVE 1: 2020-04-06 - 2020-09-17\n",
        "        if wave == 1:\n",
        "            firstDayNumber = date(2020, 4, 6).timetuple().tm_yday\n",
        "            lastDayNumber = date(2020, 9, 17).timetuple().tm_yday + 1\n",
        "        elif wave == 2:\n",
        "            firstDayNumber = date(2020, 9, 18).timetuple().tm_yday\n",
        "            lastDayNumber = date(2020, 12, 26).timetuple().tm_yday + 1\n",
        "        elif wave == 3:\n",
        "            firstDayNumber = date(2021, 1, 1).timetuple().tm_yday\n",
        "            lastDayNumber = date(2021, 4, 13).timetuple().tm_yday + 1\n",
        "            # print(lastDayNumber - firstDayNumber)\n",
        "            # dd\n",
        "\n",
        "        ODmatrix_daily_2019 = np.load(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix_daily_2019.npy\"\n",
        "        )\n",
        "        ODmatrix_daily_2020 = np.load(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix_daily_2020.npy\"\n",
        "        )\n",
        "        ODmatrix_daily_2021 = np.load(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODmatrix_daily_2021.npy\"\n",
        "        )\n",
        "\n",
        "        # ===========================================================\n",
        "        # Loading COVID data\n",
        "        # ===========================================================\n",
        "        # TODO: rows/columns meaning\n",
        "        elp_ZIP_POP_COVID = pd.read_pickle(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_COVID_DATA/elp_ZIP_POP_COVID_V2.pkl\"\n",
        "        )\n",
        "        elp_ZIP_POP_COVID.fillna(0, inplace=True)\n",
        "        # print(elp_ZIP_POP_COVID.head())\n",
        "        # ===========================================================\n",
        "\n",
        "        # ===========================================================\n",
        "        # Load the Population Matrix\n",
        "        # ===========================================================\n",
        "        population = np.load(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/PopulationMatrixACS2012_2016.npy\"\n",
        "        )\n",
        "        # ===========================================================\n",
        "\n",
        "        # ===========================================================\n",
        "        # Load the ELP CBG dictionary\n",
        "        # ===========================================================\n",
        "        ELP_CGB_dictionary = pd.read_pickle(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/ELP_CGB/ELPCGB_dictionary.pkl\"\n",
        "        )\n",
        "        # pop = np.load(\"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/PopulationMatrix3.npy\")\n",
        "        # ===========================================================\n",
        "\n",
        "        ODmatrix_daily_2020 = np.delete(ODmatrix_daily_2020, [day_of_year], axis=0)\n",
        "\n",
        "        for i in range(0, ODmatrix_daily_2019.shape[0], 1):\n",
        "            np.fill_diagonal(ODmatrix_daily_2019[i], 0)\n",
        "\n",
        "        for i in range(0, ODmatrix_daily_2020.shape[0], 1):\n",
        "            np.fill_diagonal(ODmatrix_daily_2020[i], 0)\n",
        "\n",
        "        for i in range(0, ODmatrix_daily_2021.shape[0], 1):\n",
        "            np.fill_diagonal(ODmatrix_daily_2021[i], 0)\n",
        "\n",
        "        sum2019 = ODmatrix_daily_2019.sum(axis=(1, 2))\n",
        "        sum2019[sum2019 == 0] = sum2019.mean()  #'nan'\n",
        "\n",
        "        sum2020 = ODmatrix_daily_2020.sum(axis=(1, 2))\n",
        "\n",
        "        sum2021_ = ODmatrix_daily_2021.sum(axis=(1, 2))\n",
        "        sum2021_[sum2021_ == 0] = sum2021_.mean()\n",
        "        sum2021 = np.empty(sum2019.shape[0])\n",
        "        sum2021[:] = np.nan\n",
        "        sum2021[0 : sum2021_.shape[0]] = sum2021_\n",
        "\n",
        "        mobChange = sum2019 - sum2020\n",
        "        mobChange2021 = sum2019 - sum2021\n",
        "        mobChangePercentage = 1 - ((mobChange / sum2019))\n",
        "        mobChangePercentage2021 = 1 - ((mobChange2021 / sum2019))\n",
        "\n",
        "        indexI = firstDayNumber\n",
        "        indexE = lastDayNumber\n",
        "\n",
        "        mobChangePercentage = np.nan_to_num(\n",
        "            ((mobChangePercentage[indexI:indexE])), nan=mobChangePercentage.mean()\n",
        "        )\n",
        "\n",
        "        # ===========================================================\n",
        "        # Load the O-D matrix\n",
        "        # ===========================================================\n",
        "        OD_matrices = np.load(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/SafeGraphs/SocialDistancingMetrics/ODMatrixBaseLine-2020-01-01_2021-12-31.npy\"\n",
        "        )\n",
        "        # Replace 0's with 1's (with 0's occur an error dividing by 0)\n",
        "        # OD_matrices = np.where(OD_matrices==0, 1, OD_matrices)\n",
        "        OD_matrices = np.where(OD_matrices == 0, 0.000000000000001, OD_matrices)\n",
        "        OD_matrices = OD_matrices.astype(np.float64)\n",
        "        # ===========================================================\n",
        "\n",
        "        # ===========================================================\n",
        "        # Specify the number of infected people in each CBG\n",
        "        # ===========================================================\n",
        "        initialDate = dateStart\n",
        "\n",
        "        initialInd = []\n",
        "        initial = []\n",
        "        CBG_date = elp_ZIP_POP_COVID[[\"GEOID\", initialDate]]\n",
        "        for index, row in CBG_date.iterrows():\n",
        "            # Initial CGB indices where people are infected\n",
        "            initialInd.append(getIndex(ELP_CGB_dictionary, row[\"GEOID\"]))\n",
        "            # Number of infected people in each CGB\n",
        "            initial.append(row[initialDate])\n",
        "\n",
        "        initialCases = np.zeros(CBG_date.shape[0])\n",
        "        initialCases[initialInd] = initial\n",
        "        initialCases = (initialCases * 1) / np.sum(initialCases)\n",
        "\n",
        "        # ============================================================\n",
        "        # Initial values of each CBG, Susceptible, Infected, and Recovered\n",
        "        # ============================================================\n",
        "\n",
        "        numberCBG = population.shape[1]\n",
        "\n",
        "        population = population[0]\n",
        "        aE = np.zeros(numberCBG, dtype=float)\n",
        "\n",
        "        if wave == 1:\n",
        "            # WAVE 1\n",
        "            percentage = 21.6581097 / np.sum(population)\n",
        "            infectedPeopleFitted = 21.6581097\n",
        "            # aI = initialCases*infectedPeopleFitted\n",
        "            aI = population * percentage\n",
        "        elif wave == 2:\n",
        "            # WAVE 2\n",
        "            percentage = 40.9305644 / np.sum(population)\n",
        "            infectedPeopleFitted = 40.9305644\n",
        "            aI = initialCases * infectedPeopleFitted\n",
        "            # aI = population*percentage\n",
        "        elif wave == 3:\n",
        "            # WAVE 3\n",
        "            percentage = 539.995526 / np.sum(population)\n",
        "            infectedPeopleFitted = 539.995526\n",
        "            # aI = initialCases*infectedPeopleFitted\n",
        "            aI = population * percentage\n",
        "\n",
        "        # print('AI: ',np.sum(aI))\n",
        "        aR = np.zeros(numberCBG, dtype=float)\n",
        "        aS = np.array(population - (aE + aI + aR), np.float)\n",
        "        population = aS + aE + aI + aR\n",
        "        # print('Total Population: ',np.sum(population))\n",
        "\n",
        "        # ============================================================\n",
        "        # Initial conditions\n",
        "        # ============================================================\n",
        "        S0, E0, I0, R0 = aS, aE, aI, aR\n",
        "        points = len(elpCovidCurve)\n",
        "        t = np.linspace(0, points - 1, points)\n",
        "\n",
        "        # ============================================================\n",
        "        # Mobility\n",
        "        # ============================================================\n",
        "        # Generate random mobility data\n",
        "        mobility = OD_matrices\n",
        "\n",
        "        # Fill main diagonal with 0s\n",
        "        for tm in range(0, mobility.shape[0]):\n",
        "            np.fill_diagonal(mobility[tm], 0)\n",
        "\n",
        "        # Create a copy of the mobility data\n",
        "        mobilityNorm = mobility.copy()\n",
        "\n",
        "        # Convert the population vector from row to column in order to normalize the mobility\n",
        "        pop = population.reshape(len(population), 1)\n",
        "\n",
        "        # Normalize the mobility dividing it by the population of each CBG\n",
        "        mobilityNorm = mobilityNorm / pop\n",
        "        # ============================================================\n",
        "        # Fitted parameters for each WAVE\n",
        "        # ============================================================\n",
        "\n",
        "        if wave == 1:\n",
        "            # WAVE 1\n",
        "            gamma = 0.42419584\n",
        "            delta = 0.01898470\n",
        "            beta = 2.26280976\n",
        "            tau = 0.00864778\n",
        "\n",
        "        elif wave == 2:\n",
        "            # WAVE 2\n",
        "            gamma = 0.37782941\n",
        "            delta = 1.71527631\n",
        "            beta = 0.52848914\n",
        "            tau = 0.00773372\n",
        "\n",
        "        elif wave == 3:\n",
        "            # WAVE 3\n",
        "            gamma = 0.23216184\n",
        "            delta = 1.24411741\n",
        "            beta = 0.22044555\n",
        "            tau = 0.00293696\n",
        "\n",
        "        # ============================================================\n",
        "        # Record initial conditions\n",
        "        # ============================================================\n",
        "        # Population\n",
        "        N = np.zeros((len(t), len(aS))).astype(np.float64)\n",
        "        N[0] = aS + aE + aI + aR\n",
        "        populationCBGs = N.copy()\n",
        "\n",
        "        # ============================================================\n",
        "        # Matrix to store the results: timesteps, 4 (SEIR), N.shape (# of CGB)\n",
        "        # ============================================================\n",
        "        resultsSEIR = np.zeros((len(t), 4, N.shape[1]))\n",
        "        resultsSEIR[0, 0] = S0\n",
        "        resultsSEIR[0, 1] = E0\n",
        "        resultsSEIR[0, 2] = I0\n",
        "        resultsSEIR[0, 3] = R0\n",
        "\n",
        "        # ============================================================\n",
        "        # Vectors to sum the CBG and to get the regional results\n",
        "        # ============================================================\n",
        "        totalS = np.zeros((len(t))).astype(np.float64)\n",
        "        totalE = np.zeros((len(t))).astype(np.float64)\n",
        "        totalI = np.zeros((len(t))).astype(np.float64)\n",
        "        totalR = np.zeros((len(t))).astype(np.float64)\n",
        "\n",
        "        totalS[0] = np.sum(aS)\n",
        "        totalE[0] = np.sum(aE)\n",
        "        totalI[0] = np.sum(aI)\n",
        "        totalR[0] = np.sum(aR)\n",
        "\n",
        "        # ============================================================\n",
        "        # Running the model\n",
        "        # ============================================================\n",
        "        # for cbg in range(0,N.shape[1]):\n",
        "        dfHotspots = pd.DataFrame(\n",
        "            columns=[\n",
        "                \"timestep\",\n",
        "                \"cbg\",\n",
        "                \"casesLast7Days\",\n",
        "                \"casesPreceding7days\",\n",
        "                \"casesLast7DaysPercentage\",\n",
        "                \"casesLast3Days\",\n",
        "                \"casesPreceding3Days\",\n",
        "                \"casesLast3DaysPercentage\",\n",
        "                \"casesLast30Days\",\n",
        "                \"ratio7days30days\",\n",
        "            ]\n",
        "        )\n",
        "        # dfExperiment = pd.DataFrame(columns = ['wave','timestep', 'cbg','S','E','I','R','mobRestrictionPercentage','mobilityRestrictionExperiment','daysWindow'])\n",
        "        # print('*'*40)\n",
        "\n",
        "        # ============================================================\n",
        "        # MOBILITY RESTRICTIONS\n",
        "        # ============================================================\n",
        "        mobilityRestrictionVector = np.ones((len(t), numberCBG), dtype=float)\n",
        "        if wave == 1:\n",
        "            mobilityRestrictionVector[0:60, :] = mobChangePercentage[0:60, None]\n",
        "        elif wave == 2:\n",
        "            mobilityRestrictionVector[0:36, :] = mobChangePercentage[0:36, None]\n",
        "        elif wave == 3:\n",
        "            mobilityRestrictionVector[0:85, :] = mobChangePercentage2021[0:85, None]\n",
        "\n",
        "        # dfExperiment = dfExperiment.append({'wave':wave,'timestep':0, 'cbg':cbg,'S':z[1,0],'E':z[1,1],'I':z[1,2],'R':z[1,3],'mobRestrictionPercentage':mobRestrictionPercentage,'mobilityRestrictionExperiment':mobilityRestrictionExperiment,'daysWindow':daysWindow}, ignore_index = True)\n",
        "        # mobilityRestriction = 0.1\n",
        "        for timeStep in range(1, len(t)):\n",
        "            for cbg in range(0, N.shape[1] - 10):\n",
        "\n",
        "                SEIRsum = (\n",
        "                    resultsSEIR[timeStep - 1, 0, cbg]\n",
        "                    + resultsSEIR[timeStep - 1, 1, cbg]\n",
        "                    + resultsSEIR[timeStep - 1, 2, cbg]\n",
        "                    + resultsSEIR[timeStep - 1, 3, cbg]\n",
        "                )\n",
        "\n",
        "                y0 = (\n",
        "                    resultsSEIR[timeStep - 1, 0, cbg],\n",
        "                    resultsSEIR[timeStep - 1, 1, cbg],\n",
        "                    resultsSEIR[timeStep - 1, 2, cbg],\n",
        "                    resultsSEIR[timeStep - 1, 3, cbg],\n",
        "                )\n",
        "                tspan = [t[timeStep - 1], t[timeStep]]\n",
        "\n",
        "                # mobilityRestriction = mobilityRestrictionVector[timeStep-1,cbg]\n",
        "                mobRestrictionPercentage = mobilityRestrictionVector[timeStep - 1, cbg]\n",
        "\n",
        "                outflowS = np.sum(\n",
        "                    mobilityNorm[indexStart + (timeStep - 1), cbg]\n",
        "                    * resultsSEIR[timeStep - 1, 0, cbg]\n",
        "                )\n",
        "                outflowE = np.sum(\n",
        "                    mobilityNorm[indexStart + (timeStep - 1), cbg]\n",
        "                    * resultsSEIR[timeStep - 1, 1, cbg]\n",
        "                )\n",
        "                outflowI = np.sum(\n",
        "                    mobilityNorm[indexStart + (timeStep - 1), cbg]\n",
        "                    * resultsSEIR[timeStep - 1, 2, cbg]\n",
        "                )\n",
        "                outflowR = np.sum(\n",
        "                    mobilityNorm[indexStart + (timeStep - 1), cbg]\n",
        "                    * resultsSEIR[timeStep - 1, 3, cbg]\n",
        "                )\n",
        "\n",
        "                inflowS = np.sum(\n",
        "                    (mobilityNorm[indexStart + (timeStep - 1), :, [cbg]].T)\n",
        "                    * resultsSEIR[timeStep - 1, 0, cbg]\n",
        "                )\n",
        "                inflowE = np.sum(\n",
        "                    (mobilityNorm[indexStart + (timeStep - 1), :, [cbg]].T)\n",
        "                    * resultsSEIR[timeStep - 1, 1, cbg]\n",
        "                )\n",
        "                inflowI = np.sum(\n",
        "                    (mobilityNorm[indexStart + (timeStep - 1), :, [cbg]].T)\n",
        "                    * resultsSEIR[timeStep - 1, 2, cbg]\n",
        "                )\n",
        "                inflowR = np.sum(\n",
        "                    (mobilityNorm[indexStart + (timeStep - 1), :, [cbg]].T)\n",
        "                    * resultsSEIR[timeStep - 1, 3, cbg]\n",
        "                )\n",
        "\n",
        "                popMob = N[0][cbg]\n",
        "\n",
        "                # Integrate the SIR ODEs\n",
        "                (z, d) = odeint(\n",
        "                    SEIRmobility,\n",
        "                    y0,\n",
        "                    tspan,\n",
        "                    args=(\n",
        "                        popMob,\n",
        "                        beta,\n",
        "                        gamma,\n",
        "                        delta,\n",
        "                        tau,\n",
        "                        mobRestrictionPercentage,\n",
        "                        outflowS,\n",
        "                        outflowE,\n",
        "                        outflowI,\n",
        "                        outflowR,\n",
        "                        inflowS,\n",
        "                        inflowE,\n",
        "                        inflowI,\n",
        "                        inflowR,\n",
        "                    ),\n",
        "                    full_output=1,\n",
        "                )\n",
        "\n",
        "                resultsSEIR[timeStep, 0, cbg] = z[1, 0]\n",
        "                resultsSEIR[timeStep, 1, cbg] = z[1, 1]\n",
        "                resultsSEIR[timeStep, 2, cbg] = z[1, 2]\n",
        "                resultsSEIR[timeStep, 3, cbg] = z[1, 3]\n",
        "\n",
        "                # Sum the results of each CBG to get the regional results\n",
        "                totalS[timeStep] = totalS[timeStep] + z[1, 0]\n",
        "                totalE[timeStep] = totalE[timeStep] + z[1, 1]\n",
        "                totalI[timeStep] = totalI[timeStep] + z[1, 2]\n",
        "                totalR[timeStep] = totalR[timeStep] + z[1, 3]\n",
        "\n",
        "                # 1) >100 new COVID-19 cases in the most recent 7 days,\n",
        "                # 2) an increase in the most recent 7-day COVID-19 incidence over the preceding 7-day incidence,\n",
        "                # 3) a decrease of <60% or an increase in the most recent 3-day COVID-19 incidence over the preceding 3-day incidence, and\n",
        "                # 4) the ratio of 7-day incidence/30-day incidence exceeds 0.31.\n",
        "\n",
        "                # In addition, hotspots must have met at least one of the following criteria:\n",
        "                # 1) >60% change in the most recent 3-day COVID-19 incidence, or\n",
        "                # 2) >60% change in the most recent 7-day incidence.\n",
        "                if timeStep >= 29:\n",
        "                    casesLast7Days = np.sum(\n",
        "                        resultsSEIR[timeStep - 6 : timeStep + 1, 2, cbg]\n",
        "                    )\n",
        "                    casesPreceding7days = np.sum(\n",
        "                        resultsSEIR[timeStep - 13 : timeStep - 6, 2, cbg]\n",
        "                    )\n",
        "                    casesLast7DaysPercentage = 100 - (\n",
        "                        (casesPreceding7days * 100) / casesLast7Days\n",
        "                    )\n",
        "\n",
        "                    casesLast3Days = np.sum(\n",
        "                        resultsSEIR[timeStep - 2 : timeStep + 1, 2, cbg]\n",
        "                    )\n",
        "                    casesPreceding3Days = np.sum(\n",
        "                        resultsSEIR[timeStep - 5 : timeStep - 2, 2, cbg]\n",
        "                    )\n",
        "\n",
        "                    casesLast3DaysPercentage = 100 - (\n",
        "                        (casesPreceding3Days * 100) / casesLast3Days\n",
        "                    )\n",
        "\n",
        "                    casesLast30Days = np.sum(\n",
        "                        resultsSEIR[timeStep - 29 : timeStep + 1, 2, cbg]\n",
        "                    )\n",
        "                    ratio7days30days = casesLast7Days / casesLast30Days\n",
        "\n",
        "                    if casesLast7Days > 100:\n",
        "                        if casesLast7Days > casesPreceding7days:\n",
        "                            if casesLast3Days > casesPreceding3Days:\n",
        "                                if ratio7days30days > 0.31:\n",
        "                                    if (\n",
        "                                        casesLast7DaysPercentage > 60.0\n",
        "                                        or casesLast3DaysPercentage > 60.0\n",
        "                                    ):\n",
        "                                        print(\n",
        "                                            timeStep,\n",
        "                                            \"CBG: \",\n",
        "                                            cbg,\n",
        "                                            casesLast7Days,\n",
        "                                            casesPreceding7days,\n",
        "                                            casesLast3Days,\n",
        "                                            casesPreceding3Days,\n",
        "                                            casesLast3DaysPercentage,\n",
        "                                            casesLast30Days,\n",
        "                                            ratio7days30days,\n",
        "                                        )\n",
        "                                        dfHotspots = dfHotspots.append(\n",
        "                                            {\n",
        "                                                \"timestep\": timeStep,\n",
        "                                                \"cbg\": cbg,\n",
        "                                                \"casesLast7Days\": casesLast7Days,\n",
        "                                                \"casesPreceding7days\": casesPreceding7days,\n",
        "                                                \"casesLast7DaysPercentage\": casesLast7DaysPercentage,\n",
        "                                                \"casesLast3Days\": casesLast3Days,\n",
        "                                                \"casesPreceding3Days\": casesPreceding3Days,\n",
        "                                                \"casesLast3DaysPercentage\": casesLast3DaysPercentage,\n",
        "                                                \"casesLast30Days\": casesLast30Days,\n",
        "                                                \"ratio7days30days\": ratio7days30days,\n",
        "                                            },\n",
        "                                            ignore_index=True,\n",
        "                                        )\n",
        "                                        mobRestrictionPercentage = (\n",
        "                                            mobilityRestrictionExperiment / 100\n",
        "                                        )  # mobilityRestrictionVector[timeStep-1,cbg] * (mobilityRestrictionExperiment/100)\n",
        "                                        # if daysWindow > 0:\n",
        "                                        mobilityRestrictionVector[\n",
        "                                            timeStep : timeStep + daysWindow, cbg\n",
        "                                        ] = mobRestrictionPercentage\n",
        "\n",
        "        dfHotspots.to_pickle(\n",
        "            \"/content/drive/My Drive/Colab Notebooks/Epidemic Modeling/resultsPaper/dfHotspots_wave2t\"\n",
        "            + str(wave)\n",
        "            + \"_\"\n",
        "            + str(int(mobilityRestrictionExperiment))\n",
        "            + \"_\"\n",
        "            + str(daysWindow)\n",
        "            + \".pkl\"\n",
        "        )\n",
        "display(dfHotspots)\n",
        "# ============================================================\n",
        "# Plot the regional results\n",
        "# ============================================================\n",
        "viz_test = plt\n",
        "\n",
        "viz_test.figure(figsize=(15, 10))\n",
        "\n",
        "SMALL_SIZE = 20\n",
        "MEDIUM_SIZE = 20\n",
        "BIGGER_SIZE = 60\n",
        "\n",
        "viz_test.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
        "viz_test.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
        "viz_test.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
        "viz_test.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
        "viz_test.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
        "viz_test.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "viz_test.plot(\n",
        "    t,\n",
        "    totalI,\n",
        "    \"r--\",\n",
        "    label=\"Infected\" + \"-- Max: \" + str(totalI.max()) + \" Min: \" + str(totalI.min()),\n",
        ")\n",
        "viz_test.plot(t, elpCovidCurve, \"-\", c=\"silver\", label=\"Real data\")\n",
        "\n",
        "viz_test.ylabel(\"Population\")\n",
        "viz_test.xlabel(\"time\")\n",
        "viz_test.legend(loc=\"best\")\n",
        "viz_test.show()\n",
        "\n",
        "# ============================================================\n",
        "# Plot matrix\n",
        "# ============================================================\n",
        "plt.figure(figsize=(25, 20))\n",
        "ax = plt.gca()\n",
        "im = ax.imshow(resultsSEIR[:, 2, :], cmap=\"hot_r\")\n",
        "plt.xlabel(\"CBG number\", fontsize=30)\n",
        "plt.ylabel(\"Time\", fontsize=30)\n",
        "\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "\n",
        "plt.colorbar(mappable=im, cax=cax, label=\"Number of infections\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}